{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool creates ML models with the given datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_number(s):\n",
    "    return list(filter(None, re.split(r'(\\d+)', s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our labels, separated by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_stats = [\n",
    "    'up_bytes_mean', 'up_bytes_median', 'up_bytes_std', 'up_bytes_var', 'up_bytes_skew', 'up_bytes_kurt',\n",
    "    'up_bytes_perc25', 'up_bytes_perc50', 'up_bytes_perc75', 'up_bytes_perc90',\n",
    "    'up_packet_mean', 'up_packet_median', 'up_packet_std', 'up_packet_var', 'up_packet_skew', 'up_packet_kurt',\n",
    "    'up_packet_perc25', 'up_packet_perc50', 'up_packet_perc75', 'up_packet_perc90',\n",
    "    'down_bytes_mean', 'down_bytes_median', 'down_bytes_std', 'down_bytes_var', 'down_bytes_skew', 'down_bytes_kurt',\n",
    "    'down_bytes_perc25', 'down_bytes_perc50', 'down_bytes_perc75', 'down_bytes_perc90',\n",
    "    'down_packet_mean', 'down_packet_median', 'down_packet_std', 'down_packet_var', 'down_packet_skew', 'down_packet_kurt',\n",
    "    'down_packet_perc25', 'down_packet_perc50', 'down_packet_perc75', 'down_packet_perc90']\n",
    "\n",
    "silences = ['down_bytes_silences', 'down_bytes_silence_mean', 'down_bytes_longest_silence', 'down_bytes_shortest_silence',\n",
    "           'up_bytes_silences', 'up_bytes_silence_mean', 'up_bytes_longest_silence', 'up_bytes_shortest_silence']\n",
    "\n",
    "scalogram = ['up_bytes_1max_y', 'up_bytes_2max_y', 'up_bytes_3max_y', 'up_bytes_4max_y', 'up_bytes_5max_y',\n",
    "    'up_bytes_1max_x', 'up_bytes_2max_x', 'up_bytes_3max_x', 'up_bytes_4max_x', 'up_bytes_5max_x',\n",
    "    'up_bytes_1min_y', 'up_bytes_2min_y', 'up_bytes_3min_y', 'up_bytes_4min_y', 'up_bytes_5min_y',\n",
    "    'up_bytes_1min_x', 'up_bytes_2min_x', 'up_bytes_3min_x', 'up_bytes_4min_x', 'up_bytes_5min_x',\n",
    "    'up_packet_1max_y', 'up_packet_2max_y', 'up_packet_3max_y', 'up_packet_4max_y', 'up_packet_5max_y',\n",
    "    'up_packet_1max_x', 'up_packet_2max_x', 'up_packet_3max_x', 'up_packet_4max_x', 'up_packet_5max_x',\n",
    "    'up_packet_1min_y', 'up_packet_2min_y', 'up_packet_2min_y', 'up_packet_4min_y', 'up_packet_5min_y',\n",
    "    'up_packet_1min_x', 'up_packet_2min_x', 'up_packet_3min_x', 'up_packet_4min_x', 'up_packet_5min_x',\n",
    "    'down_bytes_1max_y', 'down_bytes_2max_y', 'down_bytes_3max_y', 'down_bytes_4max_y', 'down_bytes_5max_y',\n",
    "    'down_bytes_1max_x', 'down_bytes_2max_x', 'down_bytes_3max_x', 'down_bytes_4max_x', 'down_bytes_5max_x',\n",
    "    'down_bytes_1min_y', 'down_bytes_2min_y', 'down_bytes_3min_y', 'down_bytes_4min_y', 'down_bytes_5min_y',\n",
    "    'down_bytes_1min_x', 'down_bytes_2min_x', 'down_bytes_3min_x', 'down_bytes_4min_x', 'down_bytes_5min_x',\n",
    "    'down_packet_1max_y', 'down_packet_2max_y', 'down_packet_3max_y', 'down_packet_4max_y', 'down_packet_5max_y',\n",
    "    'down_packet_1max_x', 'down_packet_2max_x', 'down_packet_3max_x', 'down_packet_4max_x', 'down_packet_5max_x',\n",
    "    'down_packet_1min_y', 'down_packet_2min_y', 'down_packet_2min_y', 'down_packet_4min_y', 'down_packet_5min_y',\n",
    "    'down_packet_1min_x', 'down_packet_2min_x', 'down_packet_3min_x', 'down_packet_4min_x', 'down_packet_5min_x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['up_bytes_mean', 'up_bytes_median', 'up_bytes_std', 'up_bytes_var',\n",
      "       'up_bytes_skew', 'up_bytes_kurt', 'up_bytes_perc25', 'up_bytes_perc50',\n",
      "       'up_bytes_perc75', 'up_bytes_perc90',\n",
      "       ...\n",
      "       'down_packet_2min_y', 'down_packet_3min_y', 'down_packet_4min_y',\n",
      "       'down_packet_5min_y', 'down_packet_1min_x', 'down_packet_2min_x',\n",
      "       'down_packet_3min_x', 'down_packet_4min_x', 'down_packet_5min_x',\n",
      "       'label'],\n",
      "      dtype='object', length=133)\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "base_folder = \"csv/\"\n",
    "file_name = 'all_30s_1s_32.csv'\n",
    "\n",
    "dataset = pd.read_csv(os.path.join(str(base_folder), str(file_name)))\n",
    "\n",
    "dataset = dataset.drop(columns=['Unnamed: 0']).reset_index()\n",
    "dataset.drop(columns=['index', 'up_packet_silence_mean', 'down_packet_silence_mean',\n",
    "                      'down_packet_longest_silence', 'down_packet_shortest_silence'], inplace=True)\n",
    "features = dataset.columns\n",
    "print(features)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the labels to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video       1644\n",
       "browsing     355\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[dataset['label'] == 'netflix-ssh', 'label'] = 'netflix'\n",
    "dataset.loc[dataset['label'] == 'youtube-ssh', 'label'] = 'youtube'\n",
    "dataset.loc[dataset['label'] == 'twitch-ssh', 'label'] = 'netflix'\n",
    "dataset.loc[dataset['label'] == 'netflix-openvpn', 'label'] = 'netflix'\n",
    "dataset.loc[dataset['label'] == 'youtube-openvpn', 'label'] = 'youtube'\n",
    "dataset.loc[dataset['label'] == 'twitch-openvpn', 'label'] = 'twitch'\n",
    "dataset.loc[dataset['label'] == 'acestream-openvpn', 'label'] = 'acestream'\n",
    "dataset.loc[dataset['label'] == 'twitch-openvpn', 'label'] = 'twitch'\n",
    "dataset.loc[dataset['label'] == 'netflix-openvpn', 'label'] = 'netflix'\n",
    "dataset.loc[dataset['label'] == 'youtube-openvpn', 'label'] = 'youtube'\n",
    "\n",
    "# Video vs. Rest\n",
    "dataset.loc[dataset['label'] == 'reddit', 'label'] = 'browsing'\n",
    "dataset.loc[dataset['label'] == 'facebook', 'label'] = 'browsing'\n",
    "dataset.loc[dataset['label'] == 'netflix', 'label'] = 'video'\n",
    "dataset.loc[dataset['label'] == 'youtube', 'label'] = 'video'\n",
    "dataset.loc[dataset['label'] == 'twitch', 'label'] = 'video'\n",
    "dataset.loc[dataset['label'] == 'acestream', 'label'] = 'video'\n",
    "\n",
    "dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factorize the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1644\n",
       "1     355\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevlabel = dataset['label']\n",
    "dataset['label'] = pd.factorize(dataset['label'])[0]\n",
    "labels = dataset['label']\n",
    "dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                          1.000000\n",
       "down_bytes_skew                0.405837\n",
       "down_bytes_kurt                0.402796\n",
       "down_bytes_1min_y              0.285368\n",
       "down_packet_skew               0.277777\n",
       "down_packet_kurt               0.255291\n",
       "down_packet_1min_y             0.247884\n",
       "up_packet_skew                 0.243054\n",
       "up_packet_1min_y               0.240381\n",
       "up_packet_kurt                 0.237944\n",
       "up_bytes_skew                  0.226234\n",
       "up_bytes_kurt                  0.197752\n",
       "down_bytes_1max_y              0.164224\n",
       "up_bytes_1max_y                0.157737\n",
       "up_bytes_1min_y                0.153485\n",
       "down_packet_1max_y             0.148639\n",
       "up_bytes_1max_x                0.143338\n",
       "up_packet_1max_y               0.133724\n",
       "up_bytes_1min_x                0.131433\n",
       "up_bytes_2min_y                0.122789\n",
       "up_bytes_2max_y                0.103522\n",
       "up_bytes_2max_x                0.098820\n",
       "down_bytes_1max_x              0.088159\n",
       "down_bytes_3max_x              0.080081\n",
       "up_packet_1max_x               0.077347\n",
       "up_packet_3max_x               0.076621\n",
       "down_packet_1max_x             0.072655\n",
       "down_bytes_3min_x              0.066455\n",
       "up_bytes_2min_x                0.063938\n",
       "up_packet_3min_y               0.062811\n",
       "                                 ...   \n",
       "up_bytes_perc90               -0.104140\n",
       "down_bytes_2max_y             -0.104246\n",
       "down_packet_std               -0.110370\n",
       "up_packet_perc50              -0.117834\n",
       "up_packet_median              -0.117834\n",
       "up_packet_mean                -0.119901\n",
       "down_packet_median            -0.124455\n",
       "down_packet_perc50            -0.124455\n",
       "down_bytes_silence_mean       -0.136660\n",
       "down_packet_perc90            -0.137685\n",
       "down_bytes_longest_silence    -0.138475\n",
       "up_packet_longest_silence     -0.138740\n",
       "up_bytes_longest_silence      -0.138740\n",
       "down_bytes_shortest_silence   -0.140564\n",
       "down_bytes_perc50             -0.140725\n",
       "down_bytes_median             -0.140725\n",
       "up_bytes_silence_mean         -0.143244\n",
       "up_packet_shortest_silence    -0.144628\n",
       "up_bytes_shortest_silence     -0.144628\n",
       "down_packet_mean              -0.145895\n",
       "up_packet_perc75              -0.151291\n",
       "down_packet_perc75            -0.152454\n",
       "down_bytes_perc75             -0.183626\n",
       "down_bytes_mean               -0.194154\n",
       "down_bytes_perc90             -0.200821\n",
       "down_bytes_std                -0.202622\n",
       "up_bytes_silences             -0.226347\n",
       "up_packet_silences            -0.226347\n",
       "down_packet_silences          -0.235256\n",
       "down_bytes_silences           -0.235256\n",
       "Name: label, Length: 133, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()['label'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputer for Nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "imputer.fit(dataset)\n",
    "dataset = pd.DataFrame(imputer.transform(dataset), columns=dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize features (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.preprocessing import normalize\\n# Normalize data\\ndataset_no_label = dataset.loc[:, dataset.columns != 'label']\\n\\n#dataset = (dataset_no_label - dataset_no_label.mean()) / (dataset_no_label.max() - dataset_no_label.min())\\ndataset_normalized = normalize(dataset_no_label)\\ndataset = pd.DataFrame(dataset_normalized, columns=features)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import normalize\n",
    "# Normalize data\n",
    "dataset_no_label = dataset.loc[:, dataset.columns != 'label']\n",
    "\n",
    "#dataset = (dataset_no_label - dataset_no_label.mean()) / (dataset_no_label.max() - dataset_no_label.min())\n",
    "dataset_normalized = normalize(dataset_no_label)\n",
    "dataset = pd.DataFrame(dataset_normalized, columns=features)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.decomposition import PCA\\npca = PCA(n_components=20)\\nmain_components = pca.fit_transform(dataset)\\ndataset = pd.DataFrame(data = main_components)\\ndataset['label'] = labels\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA\n",
    "'''\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "main_components = pca.fit_transform(dataset)\n",
    "dataset = pd.DataFrame(data = main_components)\n",
    "dataset['label'] = labels\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training and testing set randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = train['label']\n",
    "x_train = train.drop(columns=['label'])\n",
    "\n",
    "y_test = test['label']\n",
    "x_test = test.drop(columns=['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video vs. Video\n",
    "y_train_youtube = (y_train == 0)\n",
    "y_train_netflix = (y_train == 1)\n",
    "y_train_twitch = (y_train == 2)\n",
    "y_train_acestream = (y_train == 3)\n",
    "y_train_browsing = (y_train == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def do_test_forest(model):\n",
    "    \n",
    "    y_probas_y = cross_val_predict(model, x_train, y_train_youtube, cv=10, method=\"predict_proba\")\n",
    "    y_probas_n = cross_val_predict(model, x_train, y_train_netflix, cv=10, method=\"predict_proba\")\n",
    "    y_probas_t = cross_val_predict(model, x_train, y_train_twitch, cv=10, method=\"predict_proba\")\n",
    "    y_probas_a = cross_val_predict(model, x_train, y_train_acestream, cv=10, method=\"predict_proba\")\n",
    "    y_probas_b = cross_val_predict(model, x_train, y_train_browsing, cv=10, method=\"predict_proba\")\n",
    "    y_probas = cross_val_predict(model, x_train, y_train, cv=10, method=\"predict_proba\")\n",
    "    \n",
    "    y_scores_y = y_probas_y[:, 1]\n",
    "    y_scores_n = y_probas_n[:, 1]\n",
    "    y_scores_t = y_probas_t[:, 1]\n",
    "\n",
    "    fpr_y, tpr_y, thresholds_y = roc_curve(y_train_youtube, y_scores_y)\n",
    "    fpr_n, tpr_n, thresholds_n = roc_curve(y_train_netflix, y_scores_n)\n",
    "    fpr_t, tpr_t, thresholds_t = roc_curve(y_train_twitch, y_scores_t)\n",
    "    fpr_a, tpr_a, thresholds_a = roc_curve(y_train_acestream, y_scores_a)\n",
    "    fpr_b, tpr_b, thresholds_b = roc_curve(y_train_browsing, y_scores_b)\n",
    "    \n",
    "\n",
    "    plot_roc_curve(fpr_y, tpr_y, \"YouTube\")\n",
    "    plot_roc_curve(fpr_n, tpr_n, \"Netflix\")\n",
    "    plot_roc_curve(fpr_t, tpr_t, \"Twitch\")\n",
    "    plot_roc_curve(fpr_t, tpr_t, \"Acestream\")\n",
    "    plot_roc_curve(fpr_t, tpr_t, \"Browsing\")\n",
    "\n",
    "    #plot_roc_curve(fpr_forest, tpr_forest, \"Multiclass\")\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    #cvs = cross_val_score(random_forest, x_train, y_train, cv=10, scoring='accuracy')\n",
    "    #accuracy = sum(cvs)/len(cvs)\n",
    "    #print(\"Accuracy: \" + str(accuracy))\n",
    "    '''\n",
    "    cv_yt = cross_val_score(model, x_train, y_train_youtube, cv=10, scoring=\"accuracy\")\n",
    "    cv_nf = cross_val_score(model, x_train, y_train_netflix, cv=10, scoring=\"accuracy\")\n",
    "    cv_tw = cross_val_score(model, x_train, y_train_twitch, cv=10, scoring=\"accuracy\")\n",
    "    cv_mc = cross_val_score(model, x_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "    '''\n",
    "    print(\"YouTube: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_yt)/len(cv_yt)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_youtube, y_scores_y)))\n",
    "    print(\"Netflix: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_nf)/len(cv_nf)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_netflix, y_scores_n)))\n",
    "    print(\"Twitch: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_tw)/len(cv_tw)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_twitch, y_scores_t)))\n",
    "    print(\"Multiclass: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_mc)/len(cv_mc)))\n",
    "    '''\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    conf_mx = confusion_matrix(y_test, predictions)\n",
    "    plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "    print(conf_mx)\n",
    "    print(\"\\nAccuracy train set: \" + str(sum(model.predict(x_train) == y_train)/float(len(y_train))))\n",
    "    print(\"Accuracy test set: \" + str(sum(predictions == y_test)/float(len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def do_test_svm(model):    \n",
    "    '''\n",
    "    y_probas_y = cross_val_predict(model, x_train, y_train_youtube, cv=10, method=\"predict_proba\")\n",
    "    y_probas_n = cross_val_predict(model, x_train, y_train_netflix, cv=10, method=\"predict_proba\")\n",
    "    y_probas_t = cross_val_predict(model, x_train, y_train_twitch, cv=10, method=\"predict_proba\")\n",
    "    y_probas = cross_val_predict(model, x_train, y_train, cv=10, method=\"predict_proba\")\n",
    "    y_scores_y = y_probas_y[:, 1]\n",
    "    y_scores_n = y_probas_n[:, 1]\n",
    "    y_scores_t = y_probas_t[:, 1]\n",
    "    \n",
    "\n",
    "    fpr_y, tpr_y, thresholds_y = roc_curve(y_train_youtube, y_scores_y)\n",
    "    fpr_n, tpr_n, thresholds_n = roc_curve(y_train_netflix, y_scores_n)\n",
    "    fpr_t, tpr_t, thresholds_t = roc_curve(y_train_twitch, y_scores_t)\n",
    "    plot_roc_curve(fpr_y, tpr_y, \"YouTube\")\n",
    "    plot_roc_curve(fpr_n, tpr_n, \"Netflix\")\n",
    "    plot_roc_curve(fpr_t, tpr_t, \"Twitch\")\n",
    "    #plot_roc_curve(fpr_forest, tpr_forest, \"Multiclass\")\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    #cvs = cross_val_score(random_forest, x_train, y_train, cv=10, scoring='accuracy')\n",
    "    #accuracy = sum(cvs)/len(cvs)\n",
    "    #print(\"Accuracy: \" + str(accuracy))\n",
    "    '''\n",
    "    cv_yt = cross_val_score(model, x_train, y_train_youtube, cv=10, scoring=\"accuracy\")\n",
    "    cv_nf = cross_val_score(model, x_train, y_train_netflix, cv=10, scoring=\"accuracy\")\n",
    "    cv_tw = cross_val_score(model, x_train, y_train_twitch, cv=10, scoring=\"accuracy\")\n",
    "    \n",
    "    cv_mc = cross_val_score(model, x_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "    '''\n",
    "    print(\"YouTube: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_yt)/len(cv_yt)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_youtube, y_scores_y)))\n",
    "    print(\"Netflix: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_nf)/len(cv_nf)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_netflix, y_scores_n)))\n",
    "    print(\"Twitch: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_tw)/len(cv_tw)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_twitch, y_scores_t)))\n",
    "    '''\n",
    "    print(\"Multiclass: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_mc)/len(cv_mc)))\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    conf_mx = confusion_matrix(y_test, predictions)\n",
    "    plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "    print(conf_mx)\n",
    "    print(\"\\nAccuracy train set: \" + str(sum(model.predict(x_train) == y_train)/float(len(y_train))))\n",
    "    print(\"Accuracy test set: \" + str(sum(predictions == y_test)/float(len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test_knn(model):\n",
    "    \n",
    "    y_probas_y = cross_val_predict(model, x_train, y_train_youtube, cv=10, method=\"predict_proba\")\n",
    "    y_probas_n = cross_val_predict(model, x_train, y_train_netflix, cv=10, method=\"predict_proba\")\n",
    "    y_probas_t = cross_val_predict(model, x_train, y_train_twitch, cv=10, method=\"predict_proba\")\n",
    "    y_probas = cross_val_predict(model, x_train, y_train, cv=10, method=\"predict_proba\")\n",
    "    y_scores_y = y_probas_y[:, 1]\n",
    "    y_scores_n = y_probas_n[:, 1]\n",
    "    y_scores_t = y_probas_t[:, 1]\n",
    "    \n",
    "\n",
    "    fpr_y, tpr_y, thresholds_y = roc_curve(y_train_youtube, y_scores_y)\n",
    "    fpr_n, tpr_n, thresholds_n = roc_curve(y_train_netflix, y_scores_n)\n",
    "    fpr_t, tpr_t, thresholds_t = roc_curve(y_train_twitch, y_scores_t)\n",
    "    plot_roc_curve(fpr_y, tpr_y, \"YouTube\")\n",
    "    plot_roc_curve(fpr_n, tpr_n, \"Netflix\")\n",
    "    plot_roc_curve(fpr_t, tpr_t, \"Twitch\")\n",
    "    #plot_roc_curve(fpr_forest, tpr_forest, \"Multiclass\")\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    #cvs = cross_val_score(random_forest, x_train, y_train, cv=10, scoring='accuracy')\n",
    "    #accuracy = sum(cvs)/len(cvs)\n",
    "    #print(\"Accuracy: \" + str(accuracy))\n",
    "    \n",
    "    cv_yt = cross_val_score(model, x_train, y_train_youtube, cv=10, scoring=\"accuracy\")\n",
    "    cv_nf = cross_val_score(model, x_train, y_train_netflix, cv=10, scoring=\"accuracy\")\n",
    "    cv_tw = cross_val_score(model, x_train, y_train_twitch, cv=10, scoring=\"accuracy\")\n",
    "    \n",
    "    cv_mc = cross_val_score(model, x_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "    \n",
    "    print(\"YouTube: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_yt)/len(cv_yt)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_youtube, y_scores_y)))\n",
    "    print(\"Netflix: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_nf)/len(cv_nf)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_netflix, y_scores_n)))\n",
    "    print(\"Twitch: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_tw)/len(cv_tw)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_twitch, y_scores_t)))\n",
    "    \n",
    "    print(\"Multiclass: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_mc)/len(cv_mc)))\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    conf_mx = confusion_matrix(y_test, predictions)\n",
    "    plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "    print(conf_mx)\n",
    "    print(\"\\nAccuracy train set: \" + str(sum(model.predict(x_train) == y_train)/float(len(y_train))))\n",
    "    print(\"Accuracy test set: \" + str(sum(predictions == y_test)/float(len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Random Forest------\n",
      "[[1372   13]\n",
      " [  74  290]]\n",
      "\n",
      "Accuracy train set: 0.9887046039462396\n",
      "Accuracy test set: 0.9502572898799314\n",
      "-----OvO Classifier Random Forest------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "OneVsOneClassifier can not be fit when only one class is present.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-c7308d3c41ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsOneClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdo_test_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m '''\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-b767a046dc29>\u001b[0m in \u001b[0;36mdo_test_forest\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mcv_yt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_youtube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcv_nf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_netflix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mcv_tw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_twitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mcv_mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     '''\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             raise ValueError(\"OneVsOneClassifier can not be fit when only one\"\n\u001b[0m\u001b[1;32m    499\u001b[0m                              \" class is present.\")\n\u001b[1;32m    500\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: OneVsOneClassifier can not be fit when only one class is present."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABZZJREFUeJzt2zGLXeUexeH1vxOE9JlK5Y6FSFIHP0OsbE0tpPID+EVsUgQ7xdJCsLWxcNJpRAjCxdg4F7s0Iry3cIrcak7i2XNmXM9T5RwObxbs+bH3ZCaz1grQ5V+HHgBcPuFDIeFDIeFDIeFDIeFDIeG/hJm5NzM/zczTmfn40HvY3cw8mpnfZub7Q2+5CoS/o5k5SvJJkveS3Elyf2buHHYVL+HTJPcOPeKqEP7u3k3ydK3181rrjySfJ3n/wJvY0VrrmyS/H3rHVSH83b2e5JcXXj87fw+uHeFDIeHv7tckb77w+o3z9+DaEf7uvkvy9sy8NTOvJfkgyZcH3gSvRPg7Wmv9meSjJF8n+THJF2utHw67il3NzGdJvk3yzsw8m5kPD73pkMZ/y4U+7vhQSPhQSPhQSPhQSPhQSPgvaWYeHHoDr871+4vwX54vnOvN9YvwodImv8Bz69atdXJysvdzr4Kzs7McHx8fesamHj9+fOgJ/A1rrbnoMze2+ItPTk5yenq6xdFcgpkLv2645jzqQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQyHhQ6Gdwp+ZezPz08w8nZmPtx4FbOvC8GfmKMknSd5LcifJ/Zm5s/UwYDu73PHfTfJ0rfXzWuuPJJ8neX/bWcCWdgn/9SS/vPD62fl7wDW1t3/cm5kHM3M6M6dnZ2f7OhbYwC7h/5rkzRdev3H+3v9Zaz1ca91da909Pj7e1z5gA7uE/12St2fmrZl5LckHSb7cdhawpRsXfWCt9efMfJTk6yRHSR6ttX7YfBmwmQvDT5K11ldJvtp4C3BJ/OYeFBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FBI+FJq11t4PPTo6Wjdv3tz7uVyO27dvH3oCr+jJkyd5/vz5XPQ5d3woJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwoJHwodGH4M/NoZn6bme8vYxCwvV3u+J8mubfxDuASXRj+WuubJL9fwhbgkvgeHwrd2NdBM/MgyYPzP+/rWGADewt/rfUwycMkOTo6Wvs6F9g/j/pQaJcf532W5Nsk78zMs5n5cPtZwJYufNRfa92/jCHA5fGoD4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4WED4VmrbX/Q2fOkvxn7wdfDbeS/PfQI3hl//Tr9++11vFFH9ok/H+ymTlda9099A5ejev3F4/6UEj4UEj4L+/hoQfwt7h+8T0+VHLHh0LCh0LCh0LCh0LCh0L/Azdxq0m0stYsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"-----Random Forest------\")\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "do_test_forest(rf)\n",
    "\n",
    "print(\"-----OvO Classifier Random Forest------\")\n",
    "\n",
    "\n",
    "\n",
    "rf = OneVsOneClassifier(rf)\n",
    "do_test_forest(rf)\n",
    "'''\n",
    "\n",
    "print(\"----------SVM-----------\")\n",
    "svm = SVC(random_state=42, probability=True)\n",
    "do_test_svm(svm)\n",
    "\n",
    "print(\"----------Knn-----------\")\n",
    "knn = KNeighborsClassifier()\n",
    "do_test_knn(knn)\n",
    "\n",
    "print(\"-----Neural Network-----\")\n",
    "nn = MLPClassifier()\n",
    "do_test_knn(nn)\n",
    "\n",
    "\n",
    "print(\"--------AdaBoost Random Forest--------\")\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy', max_depth=9,\n",
    "                            max_features='log2', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                            min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
    "                            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1, oob_score=False,\n",
    "                            random_state=42, verbose=0, warm_start=False)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    rf,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5\n",
    ")\n",
    "do_test_forest(ada_clf)\n",
    "\n",
    "print(\"---------Decision Tree------\")\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "do_test_forest(dt)\n",
    "\n",
    "print(\"--------AdaBoost Decision Tree--------\")\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    dt,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5\n",
    ")\n",
    "do_test_forest(ada_clf)\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import GridSearchCV\\nparams = dict()\\n\\nrandom_forest = RandomForestClassifier()\\n\\nparams[\\'forest\\'] = {\\n    \\'max_depth\\' : [6,7,8,9],\\n    \\'n_estimators\\': [30,100,300],\\n    \\'criterion\\': [\\'gini\\',\\'entropy\\'],\\n    \\'max_features\\': [\\'auto\\', \\'sqrt\\', \\'log2\\'],\\n    \\'min_samples_leaf\\' : [1, 2, 4, 6, 8, 10],\\n    \\'min_samples_split\\': [2, 3, 10],\\n}\\n\\ngrid_search = GridSearchCV(random_forest, params[\\'forest\\'], cv=10, scoring=\\'accuracy\\')\\ngrid_search.fit(x_train, y_train)\\n\\nbest_random_forest = grid_search.best_estimator_\\n\\npredictions = best_random_forest.predict(x_test)\\nconf_mx = confusion_matrix(y_test, predictions)\\nplt.matshow(conf_mx, cmap=plt.cm.gray)\\nprint(conf_mx)\\nprint(\"\\nAccuracy train set: \" + str(sum(best_random_forest.predict(x_train) == y_train)/float(len(y_train))))\\nprint(\"Accuracy test set: \" + str(sum(predictions == y_test)/float(len(y_test))))\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = dict()\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "params['forest'] = {\n",
    "    'max_depth' : [6,7,8,9],\n",
    "    'n_estimators': [30,100,300],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_leaf' : [1, 2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 3, 10],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(random_forest, params['forest'], cv=10, scoring='accuracy')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_random_forest = grid_search.best_estimator_\n",
    "\n",
    "predictions = best_random_forest.predict(x_test)\n",
    "conf_mx = confusion_matrix(y_test, predictions)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "print(conf_mx)\n",
    "print(\"\\nAccuracy train set: \" + str(sum(best_random_forest.predict(x_train) == y_train)/float(len(y_train))))\n",
    "print(\"Accuracy test set: \" + str(sum(predictions == y_test)/float(len(y_test))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Random Forest------\n",
      "[[63  1  0  0]\n",
      " [ 1 52  0  2]\n",
      " [ 0  0 19  0]\n",
      " [ 1  5  0 31]]\n",
      "\n",
      "Accuracy train set: 1.0\n",
      "Accuracy test set: 0.9428571428571428\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"-----Random Forest------\")\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=9, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "do_test_forest(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/rf_model_all_60s_1s_64.csv.sav']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(rf, '../models/rf_model_' + file_name + '.sav') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.85775709 -1.36511737 -1.90905858 -1.75841844]\n",
      " [-1.30671931 -1.27479909 -3.90819891 -0.84459922]\n",
      " [-1.65517134 -0.77969983 -5.01063529 -1.06789769]\n",
      " [-0.80793102 -1.54991106 -2.71487541 -1.28829499]\n",
      " [-1.13787692 -0.89622223 -5.01063529 -1.32905958]\n",
      " [-1.46798092 -1.17841638 -5.70378247 -0.77977156]\n",
      " [-0.87102305 -1.15403153 -3.38469001 -1.46004475]\n",
      " [-1.55410649 -0.60344535 -4.60517019 -1.46232137]\n",
      " [-0.98766641 -0.94960912 -4.07990388 -1.4972086 ]\n",
      " [-1.48947032 -1.4780981  -4.60517019 -0.62280635]\n",
      " [-1.24363479 -0.71502763 -5.70378247 -1.51798154]]\n",
      "[0. 3. 1. 0. 1. 3. 0. 1. 1. 3. 1.]\n"
     ]
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(base_folder):\n",
    "    for name in files:\n",
    "        if name == 'cap3.csv':\n",
    "            test = pd.read_csv(os.path.join(str(path), str(name)))\n",
    "test = test.drop(columns=['Unnamed: 0']).reset_index()\n",
    "test.drop(columns=['index', 'up_packet_silence_mean', 'down_packet_silence_mean',\n",
    "                      'down_packet_longest_silence', 'down_packet_shortest_silence','label'], inplace=True)\n",
    "# Imputer for NaN\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "imputer.fit(test)\n",
    "test = pd.DataFrame(imputer.transform(test), columns=test.columns)\n",
    "print(rf.predict_log_proba(test))\n",
    "print(rf.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "rf = joblib.load('../models/rf_model_01s.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "4000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c6f8f2dd61c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2558\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2560\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2561\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4000"
     ]
    }
   ],
   "source": [
    "print(prevlabel[4000])\n",
    "dataset['label'][4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
