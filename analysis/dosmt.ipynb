{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_number(s):\n",
    "    return list(filter(None, re.split(r'(\\d+)', s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_stats = [\n",
    "    'up_bytes_mean', 'up_bytes_median', 'up_bytes_std', 'up_bytes_var', 'up_bytes_skew', 'up_bytes_kurt',\n",
    "    'up_bytes_perc25', 'up_bytes_perc50', 'up_bytes_perc75', 'up_bytes_perc90',\n",
    "    'up_packet_mean', 'up_packet_median', 'up_packet_std', 'up_packet_var', 'up_packet_skew', 'up_packet_kurt',\n",
    "    'up_packet_perc25', 'up_packet_perc50', 'up_packet_perc75', 'up_packet_perc90',\n",
    "    'down_bytes_mean', 'down_bytes_median', 'down_bytes_std', 'down_bytes_var', 'down_bytes_skew', 'down_bytes_kurt',\n",
    "    'down_bytes_perc25', 'down_bytes_perc50', 'down_bytes_perc75', 'down_bytes_perc90',\n",
    "    'down_packet_mean', 'down_packet_median', 'down_packet_std', 'down_packet_var', 'down_packet_skew', 'down_packet_kurt',\n",
    "    'down_packet_perc25', 'down_packet_perc50', 'down_packet_perc75', 'down_packet_perc90']\n",
    "\n",
    "silences = ['down_bytes_silences', 'down_bytes_silence_mean', 'down_bytes_longest_silence', 'down_bytes_shortest_silence',\n",
    "           'up_bytes_silences', 'up_bytes_silence_mean', 'up_bytes_longest_silence', 'up_bytes_shortest_silence']\n",
    "\n",
    "scalogram = ['up_bytes_1max_y', 'up_bytes_2max_y', 'up_bytes_3max_y', 'up_bytes_4max_y', 'up_bytes_5max_y',\n",
    "    'up_bytes_1max_x', 'up_bytes_2max_x', 'up_bytes_3max_x', 'up_bytes_4max_x', 'up_bytes_5max_x',\n",
    "    'up_bytes_1min_y', 'up_bytes_2min_y', 'up_bytes_3min_y', 'up_bytes_4min_y', 'up_bytes_5min_y',\n",
    "    'up_bytes_1min_x', 'up_bytes_2min_x', 'up_bytes_3min_x', 'up_bytes_4min_x', 'up_bytes_5min_x',\n",
    "    'up_packet_1max_y', 'up_packet_2max_y', 'up_packet_3max_y', 'up_packet_4max_y', 'up_packet_5max_y',\n",
    "    'up_packet_1max_x', 'up_packet_2max_x', 'up_packet_3max_x', 'up_packet_4max_x', 'up_packet_5max_x',\n",
    "    'up_packet_1min_y', 'up_packet_2min_y', 'up_packet_2min_y', 'up_packet_4min_y', 'up_packet_5min_y',\n",
    "    'up_packet_1min_x', 'up_packet_2min_x', 'up_packet_3min_x', 'up_packet_4min_x', 'up_packet_5min_x',\n",
    "    'down_bytes_1max_y', 'down_bytes_2max_y', 'down_bytes_3max_y', 'down_bytes_4max_y', 'down_bytes_5max_y',\n",
    "    'down_bytes_1max_x', 'down_bytes_2max_x', 'down_bytes_3max_x', 'down_bytes_4max_x', 'down_bytes_5max_x',\n",
    "    'down_bytes_1min_y', 'down_bytes_2min_y', 'down_bytes_3min_y', 'down_bytes_4min_y', 'down_bytes_5min_y',\n",
    "    'down_bytes_1min_x', 'down_bytes_2min_x', 'down_bytes_3min_x', 'down_bytes_4min_x', 'down_bytes_5min_x',\n",
    "    'down_packet_1max_y', 'down_packet_2max_y', 'down_packet_3max_y', 'down_packet_4max_y', 'down_packet_5max_y',\n",
    "    'down_packet_1max_x', 'down_packet_2max_x', 'down_packet_3max_x', 'down_packet_4max_x', 'down_packet_5max_x',\n",
    "    'down_packet_1min_y', 'down_packet_2min_y', 'down_packet_2min_y', 'down_packet_4min_y', 'down_packet_5min_y',\n",
    "    'down_packet_1min_x', 'down_packet_2min_x', 'down_packet_3min_x', 'down_packet_4min_x', 'down_packet_5min_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['up_bytes_mean', 'up_bytes_median', 'up_bytes_std', 'up_bytes_var',\n",
      "       'up_bytes_skew', 'up_bytes_kurt', 'up_bytes_perc25', 'up_bytes_perc50',\n",
      "       'up_bytes_perc75', 'up_bytes_perc90',\n",
      "       ...\n",
      "       'down_packet_2min_y', 'down_packet_3min_y', 'down_packet_4min_y',\n",
      "       'down_packet_5min_y', 'down_packet_1min_x', 'down_packet_2min_x',\n",
      "       'down_packet_3min_x', 'down_packet_4min_x', 'down_packet_5min_x',\n",
      "       'label'],\n",
      "      dtype='object', length=133)\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_folder = \"csv/30s1.00s/\"\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "for path, subdirs, files in os.walk(base_folder):\n",
    "    for name in files:\n",
    "        data = pd.read_csv(os.path.join(str(path), str(name)))\n",
    "        if(split_number(name)[0] == 'cap'):\n",
    "            continue\n",
    "        data['label'] = split_number(name)[0]\n",
    "        dataset = pd.concat([dataset, data])\n",
    "dataset = dataset.drop(columns=['Unnamed: 0']).reset_index()\n",
    "dataset.drop(columns=['index', 'up_packet_silence_mean', 'down_packet_silence_mean',\n",
    "                      'down_packet_longest_silence', 'down_packet_shortest_silence'], inplace=True)\n",
    "features = dataset.columns\n",
    "print(features)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netflix      569\n",
       "youtube      461\n",
       "acestream    248\n",
       "twitch       225\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[dataset['label'] == 'netflix-ssh', 'label'] = 'netflix'\n",
    "dataset.loc[dataset['label'] == 'youtube-ssh', 'label'] = 'youtube'\n",
    "dataset.loc[dataset['label'] == 'twitch-ssh.csv', 'label'] = 'netflix'\n",
    "dataset.loc[dataset['label'] == 'netflix-openvpn.csv', 'label'] = 'netflix'\n",
    "dataset.loc[dataset['label'] == 'youtube-openvpn.csv', 'label'] = 'youtube'\n",
    "dataset.loc[dataset['label'] == 'twitch-openvpn.csv', 'label'] = 'twitch'\n",
    "dataset.loc[dataset['label'] == 'acestream-openvpn.csv', 'label'] = 'acestream'\n",
    "dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['up_bytes_mean', 'up_bytes_median', 'up_bytes_std', 'up_bytes_var',\n",
       "       'up_bytes_skew', 'up_bytes_kurt', 'up_bytes_perc25', 'up_bytes_perc50',\n",
       "       'up_bytes_perc75', 'up_bytes_perc90',\n",
       "       ...\n",
       "       'down_packet_1min_y', 'down_packet_2min_y', 'down_packet_3min_y',\n",
       "       'down_packet_4min_y', 'down_packet_5min_y', 'down_packet_1min_x',\n",
       "       'down_packet_2min_x', 'down_packet_3min_x', 'down_packet_4min_x',\n",
       "       'down_packet_5min_x'],\n",
       "      dtype='object', length=132)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test some stuff\n",
    "#dataset.drop(columns=silences, inplace=True)\n",
    "dataset.columns\n",
    "features = dataset.columns[:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "5       0\n",
       "6       0\n",
       "7       0\n",
       "8       0\n",
       "9       0\n",
       "10      0\n",
       "11      0\n",
       "12      0\n",
       "13      0\n",
       "14      0\n",
       "15      0\n",
       "16      0\n",
       "17      0\n",
       "18      0\n",
       "19      0\n",
       "20      0\n",
       "21      0\n",
       "22      0\n",
       "23      0\n",
       "24      0\n",
       "25      0\n",
       "26      0\n",
       "27      0\n",
       "28      0\n",
       "29      0\n",
       "       ..\n",
       "1473    2\n",
       "1474    2\n",
       "1475    2\n",
       "1476    2\n",
       "1477    2\n",
       "1478    2\n",
       "1479    2\n",
       "1480    2\n",
       "1481    2\n",
       "1482    2\n",
       "1483    2\n",
       "1484    2\n",
       "1485    2\n",
       "1486    2\n",
       "1487    2\n",
       "1488    2\n",
       "1489    2\n",
       "1490    2\n",
       "1491    2\n",
       "1492    2\n",
       "1493    2\n",
       "1494    2\n",
       "1495    2\n",
       "1496    2\n",
       "1497    2\n",
       "1498    2\n",
       "1499    2\n",
       "1500    2\n",
       "1501    2\n",
       "1502    2\n",
       "Name: label, Length: 1503, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevlabel = dataset['label']\n",
    "dataset['label'] = pd.factorize(dataset['label'])[0]\n",
    "labels = dataset['label']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                          1.000000\n",
       "up_bytes_silence_mean          0.642040\n",
       "down_bytes_silence_mean        0.641925\n",
       "up_bytes_shortest_silence      0.533203\n",
       "up_packet_shortest_silence     0.533203\n",
       "down_bytes_shortest_silence    0.533203\n",
       "down_bytes_perc25              0.500448\n",
       "up_packet_longest_silence      0.460539\n",
       "up_bytes_longest_silence       0.460539\n",
       "down_packet_perc25             0.460033\n",
       "down_bytes_longest_silence     0.455390\n",
       "up_bytes_perc25                0.404766\n",
       "up_packet_perc25               0.391466\n",
       "up_packet_silences             0.331956\n",
       "up_bytes_silences              0.331956\n",
       "down_bytes_silences            0.318348\n",
       "down_packet_silences           0.318348\n",
       "down_packet_median             0.198868\n",
       "down_packet_perc50             0.198868\n",
       "up_packet_perc50               0.183013\n",
       "up_packet_median               0.183013\n",
       "down_bytes_perc50              0.178715\n",
       "down_bytes_median              0.178715\n",
       "up_bytes_median                0.132959\n",
       "up_bytes_perc50                0.132959\n",
       "down_bytes_mean               -0.006488\n",
       "down_packet_mean              -0.007788\n",
       "up_packet_mean                -0.008220\n",
       "up_bytes_mean                 -0.008907\n",
       "up_bytes_5min_x               -0.057707\n",
       "                                 ...   \n",
       "down_bytes_2max_x             -0.455066\n",
       "up_packet_2max_x              -0.455672\n",
       "up_bytes_2min_x               -0.456682\n",
       "up_packet_1max_x              -0.476059\n",
       "down_packet_2min_x            -0.477088\n",
       "up_bytes_1max_x               -0.478111\n",
       "up_packet_2min_x              -0.480164\n",
       "down_packet_1max_x            -0.485629\n",
       "down_bytes_2min_x             -0.503025\n",
       "down_bytes_2max_y             -0.516712\n",
       "down_bytes_1max_x             -0.518143\n",
       "up_packet_1min_x              -0.519181\n",
       "up_bytes_1min_x               -0.523921\n",
       "down_bytes_2min_y             -0.524426\n",
       "down_packet_2max_y            -0.524474\n",
       "up_bytes_2max_y               -0.525285\n",
       "up_packet_2max_y              -0.526027\n",
       "up_bytes_2min_y               -0.527989\n",
       "down_packet_2min_y            -0.528717\n",
       "up_packet_2min_y              -0.530965\n",
       "down_packet_1min_x            -0.535485\n",
       "up_bytes_1max_y               -0.538109\n",
       "down_packet_1max_y            -0.538228\n",
       "up_packet_1max_y              -0.538368\n",
       "up_bytes_1min_y               -0.538431\n",
       "down_bytes_1min_y             -0.538663\n",
       "down_packet_1min_y            -0.538703\n",
       "up_packet_1min_y              -0.538849\n",
       "down_bytes_1max_y             -0.539248\n",
       "down_bytes_1min_x             -0.570525\n",
       "Name: label, Length: 133, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()['label'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputer for NaN\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "imputer.fit(dataset)\n",
    "dataset = pd.DataFrame(imputer.transform(dataset), columns=dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.preprocessing import normalize\\n# Normalize data\\ndataset_no_label = dataset.loc[:, dataset.columns != 'label']\\n\\n#dataset = (dataset_no_label - dataset_no_label.mean()) / (dataset_no_label.max() - dataset_no_label.min())\\ndataset_normalized = normalize(dataset_no_label)\\ndataset = pd.DataFrame(dataset_normalized, columns=features)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import normalize\n",
    "# Normalize data\n",
    "dataset_no_label = dataset.loc[:, dataset.columns != 'label']\n",
    "\n",
    "#dataset = (dataset_no_label - dataset_no_label.mean()) / (dataset_no_label.max() - dataset_no_label.min())\n",
    "dataset_normalized = normalize(dataset_no_label)\n",
    "dataset = pd.DataFrame(dataset_normalized, columns=features)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.decomposition import PCA\\npca = PCA(n_components=10)\\nmain_components = pca.fit_transform(dataset)\\ndataset = pd.DataFrame(data = main_components)\\ndataset['label'] = labels\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA\n",
    "'''\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "main_components = pca.fit_transform(dataset)\n",
    "dataset = pd.DataFrame(data = main_components)\n",
    "dataset['label'] = labels\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = train['label']\n",
    "x_train = train.drop(columns=['label'])\n",
    "\n",
    "y_test = test['label']\n",
    "x_test = test.drop(columns=['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_youtube = (y_train == 0)\n",
    "y_train_netflix = (y_train == 1)\n",
    "y_train_twitch = (y_train == 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>up_bytes_mean</th>\n",
       "      <th>up_bytes_median</th>\n",
       "      <th>up_bytes_std</th>\n",
       "      <th>up_bytes_var</th>\n",
       "      <th>up_bytes_skew</th>\n",
       "      <th>up_bytes_kurt</th>\n",
       "      <th>up_bytes_perc25</th>\n",
       "      <th>up_bytes_perc50</th>\n",
       "      <th>up_bytes_perc75</th>\n",
       "      <th>up_bytes_perc90</th>\n",
       "      <th>...</th>\n",
       "      <th>down_packet_1min_y</th>\n",
       "      <th>down_packet_2min_y</th>\n",
       "      <th>down_packet_3min_y</th>\n",
       "      <th>down_packet_4min_y</th>\n",
       "      <th>down_packet_5min_y</th>\n",
       "      <th>down_packet_1min_x</th>\n",
       "      <th>down_packet_2min_x</th>\n",
       "      <th>down_packet_3min_x</th>\n",
       "      <th>down_packet_4min_x</th>\n",
       "      <th>down_packet_5min_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.879593</td>\n",
       "      <td>0.190769</td>\n",
       "      <td>1.404774</td>\n",
       "      <td>1.973389</td>\n",
       "      <td>1.062928</td>\n",
       "      <td>-0.276773</td>\n",
       "      <td>-0.282755</td>\n",
       "      <td>0.190769</td>\n",
       "      <td>1.441475</td>\n",
       "      <td>3.121046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005541</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.687342</td>\n",
       "      <td>9.462278</td>\n",
       "      <td>3.978398</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>0.790971</td>\n",
       "      <td>-0.075750</td>\n",
       "      <td>2.769057</td>\n",
       "      <td>7.667675</td>\n",
       "      <td>2.860182</td>\n",
       "      <td>7.127311</td>\n",
       "      <td>-0.448144</td>\n",
       "      <td>-0.075750</td>\n",
       "      <td>0.425096</td>\n",
       "      <td>1.346347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.204785</td>\n",
       "      <td>8.724062</td>\n",
       "      <td>2.579672</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0.241942</td>\n",
       "      <td>0.291678</td>\n",
       "      <td>0.800059</td>\n",
       "      <td>0.640094</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>-1.426360</td>\n",
       "      <td>-0.435217</td>\n",
       "      <td>0.291678</td>\n",
       "      <td>1.019688</td>\n",
       "      <td>1.284463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.337687</td>\n",
       "      <td>4.731139</td>\n",
       "      <td>3.186284</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.066960</td>\n",
       "      <td>-0.157837</td>\n",
       "      <td>0.529482</td>\n",
       "      <td>0.280352</td>\n",
       "      <td>4.583063</td>\n",
       "      <td>20.911806</td>\n",
       "      <td>-0.299731</td>\n",
       "      <td>-0.157837</td>\n",
       "      <td>-0.061937</td>\n",
       "      <td>0.131357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.375141</td>\n",
       "      <td>9.061108</td>\n",
       "      <td>6.547470</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>-0.235245</td>\n",
       "      <td>-0.480009</td>\n",
       "      <td>0.823406</td>\n",
       "      <td>0.677998</td>\n",
       "      <td>0.552440</td>\n",
       "      <td>-1.128294</td>\n",
       "      <td>-0.900050</td>\n",
       "      <td>-0.480009</td>\n",
       "      <td>0.496123</td>\n",
       "      <td>1.036155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.094940</td>\n",
       "      <td>8.399553</td>\n",
       "      <td>5.387767</td>\n",
       "      <td>3.381850</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.044229</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>0.643122</td>\n",
       "      <td>0.413606</td>\n",
       "      <td>1.950240</td>\n",
       "      <td>2.379129</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>1.164278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.008113</td>\n",
       "      <td>5.358670</td>\n",
       "      <td>2.752872</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>-0.122577</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>0.505231</td>\n",
       "      <td>0.255258</td>\n",
       "      <td>4.340949</td>\n",
       "      <td>19.002646</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>-0.093823</td>\n",
       "      <td>0.056036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.601893</td>\n",
       "      <td>6.069436</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>-0.234460</td>\n",
       "      <td>-0.392946</td>\n",
       "      <td>0.528559</td>\n",
       "      <td>0.279375</td>\n",
       "      <td>4.351489</td>\n",
       "      <td>18.449993</td>\n",
       "      <td>-0.392946</td>\n",
       "      <td>-0.392946</td>\n",
       "      <td>-0.338340</td>\n",
       "      <td>-0.163649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.008537</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.814342</td>\n",
       "      <td>9.411176</td>\n",
       "      <td>5.159343</td>\n",
       "      <td>3.067764</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>-0.085159</td>\n",
       "      <td>-0.392946</td>\n",
       "      <td>0.734393</td>\n",
       "      <td>0.539333</td>\n",
       "      <td>2.496723</td>\n",
       "      <td>4.720441</td>\n",
       "      <td>-0.392946</td>\n",
       "      <td>-0.392946</td>\n",
       "      <td>-0.308158</td>\n",
       "      <td>0.761831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.007884</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.974139</td>\n",
       "      <td>7.296414</td>\n",
       "      <td>4.654899</td>\n",
       "      <td>2.593679</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>-0.531207</td>\n",
       "      <td>-0.602864</td>\n",
       "      <td>0.246125</td>\n",
       "      <td>0.060577</td>\n",
       "      <td>0.854236</td>\n",
       "      <td>-0.151269</td>\n",
       "      <td>-0.725701</td>\n",
       "      <td>-0.602864</td>\n",
       "      <td>-0.375490</td>\n",
       "      <td>-0.201934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.024219</td>\n",
       "      <td>6.618767</td>\n",
       "      <td>4.043557</td>\n",
       "      <td>2.483716</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>0.046171</td>\n",
       "      <td>-0.302699</td>\n",
       "      <td>1.017337</td>\n",
       "      <td>1.034974</td>\n",
       "      <td>0.631069</td>\n",
       "      <td>-0.492149</td>\n",
       "      <td>-0.827751</td>\n",
       "      <td>-0.302699</td>\n",
       "      <td>0.891631</td>\n",
       "      <td>1.321189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.527398</td>\n",
       "      <td>8.819061</td>\n",
       "      <td>3.589418</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>-0.316214</td>\n",
       "      <td>-0.388338</td>\n",
       "      <td>0.148783</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>3.417390</td>\n",
       "      <td>12.834674</td>\n",
       "      <td>-0.392946</td>\n",
       "      <td>-0.388338</td>\n",
       "      <td>-0.303089</td>\n",
       "      <td>-0.186044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.404679</td>\n",
       "      <td>9.360350</td>\n",
       "      <td>5.626304</td>\n",
       "      <td>2.969690</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>-0.141293</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>0.467614</td>\n",
       "      <td>0.218663</td>\n",
       "      <td>4.363958</td>\n",
       "      <td>19.157104</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>-0.095536</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.676306</td>\n",
       "      <td>7.375866</td>\n",
       "      <td>5.626304</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>-0.127350</td>\n",
       "      <td>-0.282940</td>\n",
       "      <td>0.291608</td>\n",
       "      <td>0.085035</td>\n",
       "      <td>1.896845</td>\n",
       "      <td>2.751115</td>\n",
       "      <td>-0.282940</td>\n",
       "      <td>-0.282940</td>\n",
       "      <td>-0.073147</td>\n",
       "      <td>0.239581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.207534</td>\n",
       "      <td>6.069436</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>-0.054864</td>\n",
       "      <td>0.057211</td>\n",
       "      <td>0.881352</td>\n",
       "      <td>0.776781</td>\n",
       "      <td>-0.010120</td>\n",
       "      <td>-1.905677</td>\n",
       "      <td>-0.999429</td>\n",
       "      <td>0.057211</td>\n",
       "      <td>0.800028</td>\n",
       "      <td>0.901958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.010265</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.676306</td>\n",
       "      <td>9.774768</td>\n",
       "      <td>6.476941</td>\n",
       "      <td>3.345420</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.147363</td>\n",
       "      <td>-0.392946</td>\n",
       "      <td>1.316346</td>\n",
       "      <td>1.732767</td>\n",
       "      <td>3.067709</td>\n",
       "      <td>8.749733</td>\n",
       "      <td>-0.392946</td>\n",
       "      <td>-0.392946</td>\n",
       "      <td>-0.107016</td>\n",
       "      <td>1.016656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.006695</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.814342</td>\n",
       "      <td>6.441961</td>\n",
       "      <td>3.851212</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>-0.135246</td>\n",
       "      <td>-0.367182</td>\n",
       "      <td>0.580179</td>\n",
       "      <td>0.336608</td>\n",
       "      <td>2.528375</td>\n",
       "      <td>5.203109</td>\n",
       "      <td>-0.367182</td>\n",
       "      <td>-0.367182</td>\n",
       "      <td>-0.351492</td>\n",
       "      <td>0.697610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.624224</td>\n",
       "      <td>9.012173</td>\n",
       "      <td>5.329730</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>1.040847</td>\n",
       "      <td>-0.180991</td>\n",
       "      <td>2.338830</td>\n",
       "      <td>5.470128</td>\n",
       "      <td>1.693526</td>\n",
       "      <td>1.293447</td>\n",
       "      <td>-0.306988</td>\n",
       "      <td>-0.180991</td>\n",
       "      <td>0.881166</td>\n",
       "      <td>6.312532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.499008</td>\n",
       "      <td>3.893149</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>-0.121227</td>\n",
       "      <td>-0.281511</td>\n",
       "      <td>0.878496</td>\n",
       "      <td>0.771755</td>\n",
       "      <td>0.364913</td>\n",
       "      <td>-1.321413</td>\n",
       "      <td>-0.887040</td>\n",
       "      <td>-0.281511</td>\n",
       "      <td>0.780301</td>\n",
       "      <td>1.172353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.204785</td>\n",
       "      <td>9.259521</td>\n",
       "      <td>6.583022</td>\n",
       "      <td>3.363586</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-0.078083</td>\n",
       "      <td>-0.289945</td>\n",
       "      <td>0.529454</td>\n",
       "      <td>0.280322</td>\n",
       "      <td>3.926877</td>\n",
       "      <td>16.077568</td>\n",
       "      <td>-0.299731</td>\n",
       "      <td>-0.289945</td>\n",
       "      <td>0.031028</td>\n",
       "      <td>0.113449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.404679</td>\n",
       "      <td>7.828576</td>\n",
       "      <td>5.076204</td>\n",
       "      <td>2.579672</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-0.433762</td>\n",
       "      <td>-0.694101</td>\n",
       "      <td>0.558082</td>\n",
       "      <td>0.311455</td>\n",
       "      <td>0.604112</td>\n",
       "      <td>-0.916666</td>\n",
       "      <td>-0.913410</td>\n",
       "      <td>-0.694101</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>0.355445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.745137</td>\n",
       "      <td>9.462278</td>\n",
       "      <td>6.036658</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>0.755316</td>\n",
       "      <td>0.661166</td>\n",
       "      <td>1.050725</td>\n",
       "      <td>1.104023</td>\n",
       "      <td>-0.011348</td>\n",
       "      <td>-0.937439</td>\n",
       "      <td>-0.003792</td>\n",
       "      <td>0.661166</td>\n",
       "      <td>1.713314</td>\n",
       "      <td>2.043437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.774768</td>\n",
       "      <td>6.202340</td>\n",
       "      <td>3.872124</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>-0.059711</td>\n",
       "      <td>-0.329517</td>\n",
       "      <td>0.416944</td>\n",
       "      <td>0.173842</td>\n",
       "      <td>1.300658</td>\n",
       "      <td>0.550210</td>\n",
       "      <td>-0.329517</td>\n",
       "      <td>-0.329517</td>\n",
       "      <td>0.257037</td>\n",
       "      <td>0.531550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.527398</td>\n",
       "      <td>8.354190</td>\n",
       "      <td>5.535640</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>-0.025321</td>\n",
       "      <td>-0.329517</td>\n",
       "      <td>0.579593</td>\n",
       "      <td>0.335928</td>\n",
       "      <td>2.709015</td>\n",
       "      <td>8.248027</td>\n",
       "      <td>-0.329517</td>\n",
       "      <td>-0.329517</td>\n",
       "      <td>0.189186</td>\n",
       "      <td>0.522726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.878761</td>\n",
       "      <td>9.827844</td>\n",
       "      <td>5.718453</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.159796</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>0.936604</td>\n",
       "      <td>0.877227</td>\n",
       "      <td>0.702558</td>\n",
       "      <td>-0.130302</td>\n",
       "      <td>-0.660066</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>0.868560</td>\n",
       "      <td>1.428328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.381681</td>\n",
       "      <td>8.219568</td>\n",
       "      <td>3.327353</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>-0.083258</td>\n",
       "      <td>-0.219893</td>\n",
       "      <td>0.755519</td>\n",
       "      <td>0.570809</td>\n",
       "      <td>0.087442</td>\n",
       "      <td>-1.744323</td>\n",
       "      <td>-0.856840</td>\n",
       "      <td>-0.219893</td>\n",
       "      <td>0.663411</td>\n",
       "      <td>0.877458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.659460</td>\n",
       "      <td>5.476010</td>\n",
       "      <td>2.813152</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.651257</td>\n",
       "      <td>0.538394</td>\n",
       "      <td>0.584924</td>\n",
       "      <td>0.342136</td>\n",
       "      <td>0.041435</td>\n",
       "      <td>-0.898807</td>\n",
       "      <td>0.260622</td>\n",
       "      <td>0.538394</td>\n",
       "      <td>1.195620</td>\n",
       "      <td>1.427581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.539757</td>\n",
       "      <td>5.907305</td>\n",
       "      <td>2.985815</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.123157</td>\n",
       "      <td>-0.329517</td>\n",
       "      <td>0.965278</td>\n",
       "      <td>0.931761</td>\n",
       "      <td>2.498685</td>\n",
       "      <td>5.280801</td>\n",
       "      <td>-0.329517</td>\n",
       "      <td>-0.329517</td>\n",
       "      <td>0.049506</td>\n",
       "      <td>1.074038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.175177</td>\n",
       "      <td>2.551884</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0.441064</td>\n",
       "      <td>0.220340</td>\n",
       "      <td>0.897416</td>\n",
       "      <td>0.805356</td>\n",
       "      <td>1.057836</td>\n",
       "      <td>0.262432</td>\n",
       "      <td>-0.377544</td>\n",
       "      <td>0.220340</td>\n",
       "      <td>0.906553</td>\n",
       "      <td>1.932901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.415917</td>\n",
       "      <td>5.595919</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.116894</td>\n",
       "      <td>-0.561451</td>\n",
       "      <td>1.101705</td>\n",
       "      <td>1.213753</td>\n",
       "      <td>1.286285</td>\n",
       "      <td>0.228253</td>\n",
       "      <td>-0.561451</td>\n",
       "      <td>-0.561451</td>\n",
       "      <td>1.015378</td>\n",
       "      <td>1.894473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14.435633</td>\n",
       "      <td>7.871085</td>\n",
       "      <td>5.626304</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>-0.175175</td>\n",
       "      <td>-0.333609</td>\n",
       "      <td>0.325522</td>\n",
       "      <td>0.105965</td>\n",
       "      <td>2.295398</td>\n",
       "      <td>4.320104</td>\n",
       "      <td>-0.333609</td>\n",
       "      <td>-0.333609</td>\n",
       "      <td>-0.219894</td>\n",
       "      <td>0.368050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.624224</td>\n",
       "      <td>9.159777</td>\n",
       "      <td>6.800425</td>\n",
       "      <td>3.151962</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0.463139</td>\n",
       "      <td>0.699081</td>\n",
       "      <td>1.091342</td>\n",
       "      <td>1.191028</td>\n",
       "      <td>0.168037</td>\n",
       "      <td>-0.635299</td>\n",
       "      <td>-0.553795</td>\n",
       "      <td>0.699081</td>\n",
       "      <td>1.371519</td>\n",
       "      <td>1.535893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.745137</td>\n",
       "      <td>7.786298</td>\n",
       "      <td>3.437239</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.076819</td>\n",
       "      <td>-0.167623</td>\n",
       "      <td>0.339893</td>\n",
       "      <td>0.115527</td>\n",
       "      <td>2.416339</td>\n",
       "      <td>5.680700</td>\n",
       "      <td>-0.299731</td>\n",
       "      <td>-0.167623</td>\n",
       "      <td>-0.038206</td>\n",
       "      <td>0.139381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.271056</td>\n",
       "      <td>8.771433</td>\n",
       "      <td>7.178836</td>\n",
       "      <td>5.358670</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.843396</td>\n",
       "      <td>-0.349223</td>\n",
       "      <td>2.165755</td>\n",
       "      <td>4.690494</td>\n",
       "      <td>2.352895</td>\n",
       "      <td>5.061903</td>\n",
       "      <td>-0.349223</td>\n",
       "      <td>-0.349223</td>\n",
       "      <td>1.398661</td>\n",
       "      <td>2.886073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.472035</td>\n",
       "      <td>5.939381</td>\n",
       "      <td>4.481751</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>0.035771</td>\n",
       "      <td>-0.222079</td>\n",
       "      <td>1.062370</td>\n",
       "      <td>1.128631</td>\n",
       "      <td>1.007597</td>\n",
       "      <td>1.267372</td>\n",
       "      <td>-0.966108</td>\n",
       "      <td>-0.222079</td>\n",
       "      <td>0.778142</td>\n",
       "      <td>1.019775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.271056</td>\n",
       "      <td>8.676947</td>\n",
       "      <td>5.131480</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.317621</td>\n",
       "      <td>-0.301858</td>\n",
       "      <td>1.497529</td>\n",
       "      <td>2.242592</td>\n",
       "      <td>2.300571</td>\n",
       "      <td>3.683047</td>\n",
       "      <td>-0.301858</td>\n",
       "      <td>-0.301858</td>\n",
       "      <td>-0.301858</td>\n",
       "      <td>2.711141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.008505</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.071279</td>\n",
       "      <td>10.262960</td>\n",
       "      <td>6.512110</td>\n",
       "      <td>3.893149</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0.379193</td>\n",
       "      <td>-0.180991</td>\n",
       "      <td>1.091758</td>\n",
       "      <td>1.191935</td>\n",
       "      <td>1.877964</td>\n",
       "      <td>2.636222</td>\n",
       "      <td>-0.306988</td>\n",
       "      <td>-0.180991</td>\n",
       "      <td>0.672011</td>\n",
       "      <td>1.648238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.374716</td>\n",
       "      <td>5.718453</td>\n",
       "      <td>4.109784</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>-0.918785</td>\n",
       "      <td>-1.071412</td>\n",
       "      <td>0.358101</td>\n",
       "      <td>0.128236</td>\n",
       "      <td>2.429690</td>\n",
       "      <td>6.207117</td>\n",
       "      <td>-1.142039</td>\n",
       "      <td>-1.071412</td>\n",
       "      <td>-0.759355</td>\n",
       "      <td>-0.628399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.537123</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.325701</td>\n",
       "      <td>-0.854874</td>\n",
       "      <td>1.283869</td>\n",
       "      <td>1.648320</td>\n",
       "      <td>3.675725</td>\n",
       "      <td>14.590387</td>\n",
       "      <td>-0.915321</td>\n",
       "      <td>-0.854874</td>\n",
       "      <td>-0.097346</td>\n",
       "      <td>0.693909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>0.007627</td>\n",
       "      <td>0.014146</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14.435633</td>\n",
       "      <td>6.069436</td>\n",
       "      <td>4.385716</td>\n",
       "      <td>2.693884</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>0.029790</td>\n",
       "      <td>0.027386</td>\n",
       "      <td>0.682170</td>\n",
       "      <td>0.465355</td>\n",
       "      <td>0.103509</td>\n",
       "      <td>-1.072488</td>\n",
       "      <td>-0.572938</td>\n",
       "      <td>0.027386</td>\n",
       "      <td>0.631800</td>\n",
       "      <td>0.906277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.883923</td>\n",
       "      <td>8.264199</td>\n",
       "      <td>4.940604</td>\n",
       "      <td>3.169077</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.184518</td>\n",
       "      <td>-0.285052</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.747200</td>\n",
       "      <td>2.480643</td>\n",
       "      <td>5.674589</td>\n",
       "      <td>-0.299731</td>\n",
       "      <td>-0.285052</td>\n",
       "      <td>0.363255</td>\n",
       "      <td>0.765009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.934862</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.304366</td>\n",
       "      <td>0.333012</td>\n",
       "      <td>0.720555</td>\n",
       "      <td>0.519199</td>\n",
       "      <td>0.570281</td>\n",
       "      <td>-0.057776</td>\n",
       "      <td>-0.251205</td>\n",
       "      <td>0.333012</td>\n",
       "      <td>0.678332</td>\n",
       "      <td>1.265597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14.050017</td>\n",
       "      <td>6.690841</td>\n",
       "      <td>3.789152</td>\n",
       "      <td>2.782849</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-0.009374</td>\n",
       "      <td>-0.301858</td>\n",
       "      <td>0.773140</td>\n",
       "      <td>0.597745</td>\n",
       "      <td>2.820108</td>\n",
       "      <td>7.202909</td>\n",
       "      <td>-0.301858</td>\n",
       "      <td>-0.301858</td>\n",
       "      <td>-0.252161</td>\n",
       "      <td>1.005622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.748954</td>\n",
       "      <td>8.583479</td>\n",
       "      <td>5.971631</td>\n",
       "      <td>3.608908</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>-0.137316</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>0.469088</td>\n",
       "      <td>0.220043</td>\n",
       "      <td>4.183836</td>\n",
       "      <td>17.805272</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>-0.306907</td>\n",
       "      <td>-0.120730</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.207534</td>\n",
       "      <td>6.202340</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0.078626</td>\n",
       "      <td>-0.257002</td>\n",
       "      <td>1.090941</td>\n",
       "      <td>1.190152</td>\n",
       "      <td>2.876347</td>\n",
       "      <td>8.014288</td>\n",
       "      <td>-0.461209</td>\n",
       "      <td>-0.257002</td>\n",
       "      <td>0.100201</td>\n",
       "      <td>0.583710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.138872</td>\n",
       "      <td>3.830413</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-0.142562</td>\n",
       "      <td>-0.306988</td>\n",
       "      <td>0.485418</td>\n",
       "      <td>0.235631</td>\n",
       "      <td>3.284539</td>\n",
       "      <td>9.178319</td>\n",
       "      <td>-0.306988</td>\n",
       "      <td>-0.306988</td>\n",
       "      <td>-0.271079</td>\n",
       "      <td>-0.059277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.271056</td>\n",
       "      <td>3.570033</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.571749</td>\n",
       "      <td>0.810318</td>\n",
       "      <td>1.133942</td>\n",
       "      <td>1.285825</td>\n",
       "      <td>0.534979</td>\n",
       "      <td>0.187865</td>\n",
       "      <td>-0.429455</td>\n",
       "      <td>0.810318</td>\n",
       "      <td>1.297547</td>\n",
       "      <td>1.832821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14.126307</td>\n",
       "      <td>7.375866</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202 rows  132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      up_bytes_mean  up_bytes_median  up_bytes_std  up_bytes_var  \\\n",
       "799        0.879593         0.190769      1.404774      1.973389   \n",
       "1349       0.790971        -0.075750      2.769057      7.667675   \n",
       "1428       0.241942         0.291678      0.800059      0.640094   \n",
       "1150       0.000000         0.000000      0.000000      0.000000   \n",
       "1100       0.000000         0.000000      0.000000      0.000000   \n",
       "342       -0.066960        -0.157837      0.529482      0.280352   \n",
       "1490      -0.235245        -0.480009      0.823406      0.677998   \n",
       "1031       0.044229        -0.306907      0.643122      0.413606   \n",
       "1047      -0.122577        -0.306907      0.505231      0.255258   \n",
       "552       -0.234460        -0.392946      0.528559      0.279375   \n",
       "1083       0.000000         0.000000      0.000000      0.000000   \n",
       "506       -0.085159        -0.392946      0.734393      0.539333   \n",
       "427       -0.531207        -0.602864      0.246125      0.060577   \n",
       "1485       0.046171        -0.302699      1.017337      1.034974   \n",
       "543       -0.316214        -0.388338      0.148783      0.022137   \n",
       "1052      -0.141293        -0.306907      0.467614      0.218663   \n",
       "1176       0.000000         0.000000      0.000000      0.000000   \n",
       "1132       0.000000         0.000000      0.000000      0.000000   \n",
       "254       -0.127350        -0.282940      0.291608      0.085035   \n",
       "1097       0.000000         0.000000      0.000000      0.000000   \n",
       "1250      -0.054864         0.057211      0.881352      0.776781   \n",
       "560        0.147363        -0.392946      1.316346      1.732767   \n",
       "672       -0.135246        -0.367182      0.580179      0.336608   \n",
       "846        1.040847        -0.180991      2.338830      5.470128   \n",
       "1492      -0.121227        -0.281511      0.878496      0.771755   \n",
       "332       -0.078083        -0.289945      0.529454      0.280322   \n",
       "86        -0.433762        -0.694101      0.558082      0.311455   \n",
       "1424       0.755316         0.661166      1.050725      1.104023   \n",
       "265       -0.059711        -0.329517      0.416944      0.173842   \n",
       "287       -0.025321        -0.329517      0.579593      0.335928   \n",
       "...             ...              ...           ...           ...   \n",
       "21         0.159796         0.024389      0.936604      0.877227   \n",
       "1337      -0.083258        -0.219893      0.755519      0.570809   \n",
       "459        0.651257         0.538394      0.584924      0.342136   \n",
       "1184       0.000000         0.000000      0.000000      0.000000   \n",
       "276        0.123157        -0.329517      0.965278      0.931761   \n",
       "955        0.441064         0.220340      0.897416      0.805356   \n",
       "1215       0.000000         0.000000      0.000000      0.000000   \n",
       "385        0.116894        -0.561451      1.101705      1.213753   \n",
       "805       -0.175175        -0.333609      0.325522      0.105965   \n",
       "1437       0.463139         0.699081      1.091342      1.191028   \n",
       "343       -0.076819        -0.167623      0.339893      0.115527   \n",
       "769        0.843396        -0.349223      2.165755      4.690494   \n",
       "1332       0.035771        -0.222079      1.062370      1.128631   \n",
       "130        0.317621        -0.301858      1.497529      2.242592   \n",
       "871        0.379193        -0.180991      1.091758      1.191935   \n",
       "1123       0.000000         0.000000      0.000000      0.000000   \n",
       "1396      -0.918785        -1.071412      0.358101      0.128236   \n",
       "87        -0.325701        -0.854874      1.283869      1.648320   \n",
       "1482       0.029790         0.027386      0.682170      0.465355   \n",
       "330        0.184518        -0.285052      0.864407      0.747200   \n",
       "1238       0.000000         0.000000      0.000000      0.000000   \n",
       "466        0.304366         0.333012      0.720555      0.519199   \n",
       "121       -0.009374        -0.301858      0.773140      0.597745   \n",
       "1044      -0.137316        -0.306907      0.469088      0.220043   \n",
       "1095       0.000000         0.000000      0.000000      0.000000   \n",
       "1130       0.000000         0.000000      0.000000      0.000000   \n",
       "1294       0.078626        -0.257002      1.090941      1.190152   \n",
       "860       -0.142562        -0.306988      0.485418      0.235631   \n",
       "1459       0.571749         0.810318      1.133942      1.285825   \n",
       "1126       0.000000         0.000000      0.000000      0.000000   \n",
       "\n",
       "      up_bytes_skew  up_bytes_kurt  up_bytes_perc25  up_bytes_perc50  \\\n",
       "799        1.062928      -0.276773        -0.282755         0.190769   \n",
       "1349       2.860182       7.127311        -0.448144        -0.075750   \n",
       "1428      -0.021780      -1.426360        -0.435217         0.291678   \n",
       "1150       0.000000      -3.000000         0.000000         0.000000   \n",
       "1100       0.000000      -3.000000         0.000000         0.000000   \n",
       "342        4.583063      20.911806        -0.299731        -0.157837   \n",
       "1490       0.552440      -1.128294        -0.900050        -0.480009   \n",
       "1031       1.950240       2.379129        -0.306907        -0.306907   \n",
       "1047       4.340949      19.002646        -0.306907        -0.306907   \n",
       "552        4.351489      18.449993        -0.392946        -0.392946   \n",
       "1083       0.000000      -3.000000         0.000000         0.000000   \n",
       "506        2.496723       4.720441        -0.392946        -0.392946   \n",
       "427        0.854236      -0.151269        -0.725701        -0.602864   \n",
       "1485       0.631069      -0.492149        -0.827751        -0.302699   \n",
       "543        3.417390      12.834674        -0.392946        -0.388338   \n",
       "1052       4.363958      19.157104        -0.306907        -0.306907   \n",
       "1176       0.000000      -3.000000         0.000000         0.000000   \n",
       "1132       0.000000      -3.000000         0.000000         0.000000   \n",
       "254        1.896845       2.751115        -0.282940        -0.282940   \n",
       "1097       0.000000      -3.000000         0.000000         0.000000   \n",
       "1250      -0.010120      -1.905677        -0.999429         0.057211   \n",
       "560        3.067709       8.749733        -0.392946        -0.392946   \n",
       "672        2.528375       5.203109        -0.367182        -0.367182   \n",
       "846        1.693526       1.293447        -0.306988        -0.180991   \n",
       "1492       0.364913      -1.321413        -0.887040        -0.281511   \n",
       "332        3.926877      16.077568        -0.299731        -0.289945   \n",
       "86         0.604112      -0.916666        -0.913410        -0.694101   \n",
       "1424      -0.011348      -0.937439        -0.003792         0.661166   \n",
       "265        1.300658       0.550210        -0.329517        -0.329517   \n",
       "287        2.709015       8.248027        -0.329517        -0.329517   \n",
       "...             ...            ...              ...              ...   \n",
       "21         0.702558      -0.130302        -0.660066         0.024389   \n",
       "1337       0.087442      -1.744323        -0.856840        -0.219893   \n",
       "459        0.041435      -0.898807         0.260622         0.538394   \n",
       "1184       0.000000      -3.000000         0.000000         0.000000   \n",
       "276        2.498685       5.280801        -0.329517        -0.329517   \n",
       "955        1.057836       0.262432        -0.377544         0.220340   \n",
       "1215       0.000000      -3.000000         0.000000         0.000000   \n",
       "385        1.286285       0.228253        -0.561451        -0.561451   \n",
       "805        2.295398       4.320104        -0.333609        -0.333609   \n",
       "1437       0.168037      -0.635299        -0.553795         0.699081   \n",
       "343        2.416339       5.680700        -0.299731        -0.167623   \n",
       "769        2.352895       5.061903        -0.349223        -0.349223   \n",
       "1332       1.007597       1.267372        -0.966108        -0.222079   \n",
       "130        2.300571       3.683047        -0.301858        -0.301858   \n",
       "871        1.877964       2.636222        -0.306988        -0.180991   \n",
       "1123       0.000000      -3.000000         0.000000         0.000000   \n",
       "1396       2.429690       6.207117        -1.142039        -1.071412   \n",
       "87         3.675725      14.590387        -0.915321        -0.854874   \n",
       "1482       0.103509      -1.072488        -0.572938         0.027386   \n",
       "330        2.480643       5.674589        -0.299731        -0.285052   \n",
       "1238       0.000000      -3.000000         0.000000         0.000000   \n",
       "466        0.570281      -0.057776        -0.251205         0.333012   \n",
       "121        2.820108       7.202909        -0.301858        -0.301858   \n",
       "1044       4.183836      17.805272        -0.306907        -0.306907   \n",
       "1095       0.000000      -3.000000         0.000000         0.000000   \n",
       "1130       0.000000      -3.000000         0.000000         0.000000   \n",
       "1294       2.876347       8.014288        -0.461209        -0.257002   \n",
       "860        3.284539       9.178319        -0.306988        -0.306988   \n",
       "1459       0.534979       0.187865        -0.429455         0.810318   \n",
       "1126       0.000000      -3.000000         0.000000         0.000000   \n",
       "\n",
       "      up_bytes_perc75  up_bytes_perc90         ...          \\\n",
       "799          1.441475         3.121046         ...           \n",
       "1349         0.425096         1.346347         ...           \n",
       "1428         1.019688         1.284463         ...           \n",
       "1150         0.000000         0.000000         ...           \n",
       "1100         0.000000         0.000000         ...           \n",
       "342         -0.061937         0.131357         ...           \n",
       "1490         0.496123         1.036155         ...           \n",
       "1031         0.005425         1.164278         ...           \n",
       "1047        -0.093823         0.056036         ...           \n",
       "552         -0.338340        -0.163649         ...           \n",
       "1083         0.000000         0.000000         ...           \n",
       "506         -0.308158         0.761831         ...           \n",
       "427         -0.375490        -0.201934         ...           \n",
       "1485         0.891631         1.321189         ...           \n",
       "543         -0.303089        -0.186044         ...           \n",
       "1052        -0.095536         0.007278         ...           \n",
       "1176         0.000000         0.000000         ...           \n",
       "1132         0.000000         0.000000         ...           \n",
       "254         -0.073147         0.239581         ...           \n",
       "1097         0.000000         0.000000         ...           \n",
       "1250         0.800028         0.901958         ...           \n",
       "560         -0.107016         1.016656         ...           \n",
       "672         -0.351492         0.697610         ...           \n",
       "846          0.881166         6.312532         ...           \n",
       "1492         0.780301         1.172353         ...           \n",
       "332          0.031028         0.113449         ...           \n",
       "86           0.018125         0.355445         ...           \n",
       "1424         1.713314         2.043437         ...           \n",
       "265          0.257037         0.531550         ...           \n",
       "287          0.189186         0.522726         ...           \n",
       "...               ...              ...         ...           \n",
       "21           0.868560         1.428328         ...           \n",
       "1337         0.663411         0.877458         ...           \n",
       "459          1.195620         1.427581         ...           \n",
       "1184         0.000000         0.000000         ...           \n",
       "276          0.049506         1.074038         ...           \n",
       "955          0.906553         1.932901         ...           \n",
       "1215         0.000000         0.000000         ...           \n",
       "385          1.015378         1.894473         ...           \n",
       "805         -0.219894         0.368050         ...           \n",
       "1437         1.371519         1.535893         ...           \n",
       "343         -0.038206         0.139381         ...           \n",
       "769          1.398661         2.886073         ...           \n",
       "1332         0.778142         1.019775         ...           \n",
       "130         -0.301858         2.711141         ...           \n",
       "871          0.672011         1.648238         ...           \n",
       "1123         0.000000         0.000000         ...           \n",
       "1396        -0.759355        -0.628399         ...           \n",
       "87          -0.097346         0.693909         ...           \n",
       "1482         0.631800         0.906277         ...           \n",
       "330          0.363255         0.765009         ...           \n",
       "1238         0.000000         0.000000         ...           \n",
       "466          0.678332         1.265597         ...           \n",
       "121         -0.252161         1.005622         ...           \n",
       "1044        -0.120730         0.012687         ...           \n",
       "1095         0.000000         0.000000         ...           \n",
       "1130         0.000000         0.000000         ...           \n",
       "1294         0.100201         0.583710         ...           \n",
       "860         -0.271079        -0.059277         ...           \n",
       "1459         1.297547         1.832821         ...           \n",
       "1126         0.000000         0.000000         ...           \n",
       "\n",
       "      down_packet_1min_y  down_packet_2min_y  down_packet_3min_y  \\\n",
       "799             0.005541            0.005882            0.002673   \n",
       "1349            0.010373            0.012255            0.001311   \n",
       "1428            0.002020            0.002768            0.003387   \n",
       "1150           -1.000000           -1.000000           -1.000000   \n",
       "1100           -1.000000           -1.000000           -1.000000   \n",
       "342             0.001820            0.001571            0.001115   \n",
       "1490            0.000560            0.001814            0.006084   \n",
       "1031            0.001106            0.003724            0.007195   \n",
       "1047            0.000692            0.003916           -1.000000   \n",
       "552             0.003720            0.009495            0.006065   \n",
       "1083           -1.000000           -1.000000           -1.000000   \n",
       "506             0.001075            0.004829            0.009290   \n",
       "427             0.007986            0.001834            0.006710   \n",
       "1485            0.000709            0.003803            0.001723   \n",
       "543             0.004973            0.008693            0.005141   \n",
       "1052            0.001653            0.001314            0.001238   \n",
       "1176           -1.000000           -1.000000           -1.000000   \n",
       "1132           -1.000000           -1.000000           -1.000000   \n",
       "254             0.001202            0.002211           -1.000000   \n",
       "1097           -1.000000           -1.000000           -1.000000   \n",
       "1250            0.001552            0.003781            0.006496   \n",
       "560             0.008325            0.006695            0.004920   \n",
       "672             0.006585            0.006503            0.007408   \n",
       "846             0.005173            0.005421           -1.000000   \n",
       "1492            0.001110            0.001606            0.001418   \n",
       "332             0.006376            0.003536            0.003956   \n",
       "86              0.002743            0.006736            0.005945   \n",
       "1424            0.003337            0.004975            0.002524   \n",
       "265             0.000256            0.001486            0.001797   \n",
       "287             0.001167            0.001534            0.000728   \n",
       "...                  ...                 ...                 ...   \n",
       "21              0.000206            0.000694            0.008029   \n",
       "1337            0.000429            0.002900            0.017167   \n",
       "459             0.003875            0.013800            0.004205   \n",
       "1184           -1.000000           -1.000000           -1.000000   \n",
       "276             0.000392            0.004428           -1.000000   \n",
       "955             0.000414            0.000893           -1.000000   \n",
       "1215           -1.000000           -1.000000           -1.000000   \n",
       "385             0.000033            0.000557            0.001251   \n",
       "805             0.003703            0.003464            0.003909   \n",
       "1437            0.005545            0.002774            0.002454   \n",
       "343             0.001917            0.002531            0.002744   \n",
       "769             0.009843            0.002733            0.002072   \n",
       "1332            0.001511            0.001764            0.007131   \n",
       "130             0.004037            0.004052            0.008505   \n",
       "871             0.001540            0.006192            0.005860   \n",
       "1123           -1.000000           -1.000000           -1.000000   \n",
       "1396            0.002066           -1.000000           -1.000000   \n",
       "87              0.000123            0.004585            0.007627   \n",
       "1482            0.001218            0.002114            0.007851   \n",
       "330             0.000254           -1.000000           -1.000000   \n",
       "1238           -1.000000           -1.000000           -1.000000   \n",
       "466             0.002266            0.004033            0.002793   \n",
       "121             0.001744            0.014836            0.003817   \n",
       "1044            0.000527            0.003140           -1.000000   \n",
       "1095           -1.000000           -1.000000           -1.000000   \n",
       "1130           -1.000000           -1.000000           -1.000000   \n",
       "1294            0.001293            0.007298           -1.000000   \n",
       "860             0.011339            0.001499           -1.000000   \n",
       "1459            0.000715            0.003308           -1.000000   \n",
       "1126           -1.000000           -1.000000           -1.000000   \n",
       "\n",
       "      down_packet_4min_y  down_packet_5min_y  down_packet_1min_x  \\\n",
       "799            -1.000000                -1.0           11.687342   \n",
       "1349           -1.000000                -1.0           12.204785   \n",
       "1428           -1.000000                -1.0           12.337687   \n",
       "1150           -1.000000                -1.0           -1.000000   \n",
       "1100           -1.000000                -1.0           -1.000000   \n",
       "342            -1.000000                -1.0           11.375141   \n",
       "1490            0.006997                -1.0           13.094940   \n",
       "1031           -1.000000                -1.0           12.008113   \n",
       "1047           -1.000000                -1.0           10.601893   \n",
       "552             0.008537                -1.0           12.814342   \n",
       "1083           -1.000000                -1.0           -1.000000   \n",
       "506             0.007884                -1.0           13.974139   \n",
       "427             0.005331                -1.0           13.024219   \n",
       "1485           -1.000000                -1.0           13.527398   \n",
       "543             0.005419                -1.0           12.404679   \n",
       "1052           -1.000000                -1.0           12.676306   \n",
       "1176           -1.000000                -1.0           -1.000000   \n",
       "1132           -1.000000                -1.0           -1.000000   \n",
       "254            -1.000000                -1.0           10.207534   \n",
       "1097           -1.000000                -1.0           -1.000000   \n",
       "1250            0.010265                -1.0           12.676306   \n",
       "560            -1.000000                -1.0           12.814342   \n",
       "672            -1.000000                -1.0           11.624224   \n",
       "846            -1.000000                -1.0           11.499008   \n",
       "1492            0.001720                -1.0           12.204785   \n",
       "332             0.003491                -1.0           12.404679   \n",
       "86             -1.000000                -1.0           12.745137   \n",
       "1424           -1.000000                -1.0            9.774768   \n",
       "265            -1.000000                -1.0           13.527398   \n",
       "287            -1.000000                -1.0           11.878761   \n",
       "...                  ...                 ...                 ...   \n",
       "21             -1.000000                -1.0           13.381681   \n",
       "1337           -1.000000                -1.0           10.659460   \n",
       "459            -1.000000                -1.0           12.539757   \n",
       "1184           -1.000000                -1.0           -1.000000   \n",
       "276            -1.000000                -1.0            8.175177   \n",
       "955            -1.000000                -1.0            7.415917   \n",
       "1215           -1.000000                -1.0           -1.000000   \n",
       "385            -1.000000                -1.0           14.435633   \n",
       "805             0.006440                -1.0           11.624224   \n",
       "1437           -1.000000                -1.0           12.745137   \n",
       "343             0.001829                -1.0           12.271056   \n",
       "769            -1.000000                -1.0           12.472035   \n",
       "1332           -1.000000                -1.0           12.271056   \n",
       "130             0.005523                -1.0           11.071279   \n",
       "871            -1.000000                -1.0           10.374716   \n",
       "1123           -1.000000                -1.0           -1.000000   \n",
       "1396           -1.000000                -1.0            8.537123   \n",
       "87              0.014146                -1.0           14.435633   \n",
       "1482            0.007918                -1.0           12.883923   \n",
       "330            -1.000000                -1.0            9.934862   \n",
       "1238           -1.000000                -1.0           -1.000000   \n",
       "466             0.001632                -1.0           14.050017   \n",
       "121             0.006444                -1.0           13.748954   \n",
       "1044           -1.000000                -1.0           10.207534   \n",
       "1095           -1.000000                -1.0           -1.000000   \n",
       "1130           -1.000000                -1.0           -1.000000   \n",
       "1294           -1.000000                -1.0           12.138872   \n",
       "860            -1.000000                -1.0           12.271056   \n",
       "1459           -1.000000                -1.0           14.126307   \n",
       "1126           -1.000000                -1.0           -1.000000   \n",
       "\n",
       "      down_packet_2min_x  down_packet_3min_x  down_packet_4min_x  \\\n",
       "799             9.462278            3.978398           -1.000000   \n",
       "1349            8.724062            2.579672           -1.000000   \n",
       "1428            4.731139            3.186284           -1.000000   \n",
       "1150           -1.000000           -1.000000           -1.000000   \n",
       "1100           -1.000000           -1.000000           -1.000000   \n",
       "342             9.061108            6.547470           -1.000000   \n",
       "1490            8.399553            5.387767            3.381850   \n",
       "1031            5.358670            2.752872           -1.000000   \n",
       "1047            6.069436           -1.000000           -1.000000   \n",
       "552             9.411176            5.159343            3.067764   \n",
       "1083           -1.000000           -1.000000           -1.000000   \n",
       "506             7.296414            4.654899            2.593679   \n",
       "427             6.618767            4.043557            2.483716   \n",
       "1485            8.819061            3.589418           -1.000000   \n",
       "543             9.360350            5.626304            2.969690   \n",
       "1052            7.375866            5.626304           -1.000000   \n",
       "1176           -1.000000           -1.000000           -1.000000   \n",
       "1132           -1.000000           -1.000000           -1.000000   \n",
       "254             6.069436           -1.000000           -1.000000   \n",
       "1097           -1.000000           -1.000000           -1.000000   \n",
       "1250            9.774768            6.476941            3.345420   \n",
       "560             6.441961            3.851212           -1.000000   \n",
       "672             9.012173            5.329730           -1.000000   \n",
       "846             3.893149           -1.000000           -1.000000   \n",
       "1492            9.259521            6.583022            3.363586   \n",
       "332             7.828576            5.076204            2.579672   \n",
       "86              9.462278            6.036658           -1.000000   \n",
       "1424            6.202340            3.872124           -1.000000   \n",
       "265             8.354190            5.535640           -1.000000   \n",
       "287             9.827844            5.718453           -1.000000   \n",
       "...                  ...                 ...                 ...   \n",
       "21              8.219568            3.327353           -1.000000   \n",
       "1337            5.476010            2.813152           -1.000000   \n",
       "459             5.907305            2.985815           -1.000000   \n",
       "1184           -1.000000           -1.000000           -1.000000   \n",
       "276             2.551884           -1.000000           -1.000000   \n",
       "955             5.595919           -1.000000           -1.000000   \n",
       "1215           -1.000000           -1.000000           -1.000000   \n",
       "385             7.871085            5.626304           -1.000000   \n",
       "805             9.159777            6.800425            3.151962   \n",
       "1437            7.786298            3.437239           -1.000000   \n",
       "343             8.771433            7.178836            5.358670   \n",
       "769             5.939381            4.481751           -1.000000   \n",
       "1332            8.676947            5.131480           -1.000000   \n",
       "130            10.262960            6.512110            3.893149   \n",
       "871             5.718453            4.109784           -1.000000   \n",
       "1123           -1.000000           -1.000000           -1.000000   \n",
       "1396           -1.000000           -1.000000           -1.000000   \n",
       "87              6.069436            4.385716            2.693884   \n",
       "1482            8.264199            4.940604            3.169077   \n",
       "330            -1.000000           -1.000000           -1.000000   \n",
       "1238           -1.000000           -1.000000           -1.000000   \n",
       "466             6.690841            3.789152            2.782849   \n",
       "121             8.583479            5.971631            3.608908   \n",
       "1044            6.202340           -1.000000           -1.000000   \n",
       "1095           -1.000000           -1.000000           -1.000000   \n",
       "1130           -1.000000           -1.000000           -1.000000   \n",
       "1294            3.830413           -1.000000           -1.000000   \n",
       "860             3.570033           -1.000000           -1.000000   \n",
       "1459            7.375866           -1.000000           -1.000000   \n",
       "1126           -1.000000           -1.000000           -1.000000   \n",
       "\n",
       "      down_packet_5min_x  \n",
       "799                 -1.0  \n",
       "1349                -1.0  \n",
       "1428                -1.0  \n",
       "1150                -1.0  \n",
       "1100                -1.0  \n",
       "342                 -1.0  \n",
       "1490                -1.0  \n",
       "1031                -1.0  \n",
       "1047                -1.0  \n",
       "552                 -1.0  \n",
       "1083                -1.0  \n",
       "506                 -1.0  \n",
       "427                 -1.0  \n",
       "1485                -1.0  \n",
       "543                 -1.0  \n",
       "1052                -1.0  \n",
       "1176                -1.0  \n",
       "1132                -1.0  \n",
       "254                 -1.0  \n",
       "1097                -1.0  \n",
       "1250                -1.0  \n",
       "560                 -1.0  \n",
       "672                 -1.0  \n",
       "846                 -1.0  \n",
       "1492                -1.0  \n",
       "332                 -1.0  \n",
       "86                  -1.0  \n",
       "1424                -1.0  \n",
       "265                 -1.0  \n",
       "287                 -1.0  \n",
       "...                  ...  \n",
       "21                  -1.0  \n",
       "1337                -1.0  \n",
       "459                 -1.0  \n",
       "1184                -1.0  \n",
       "276                 -1.0  \n",
       "955                 -1.0  \n",
       "1215                -1.0  \n",
       "385                 -1.0  \n",
       "805                 -1.0  \n",
       "1437                -1.0  \n",
       "343                 -1.0  \n",
       "769                 -1.0  \n",
       "1332                -1.0  \n",
       "130                 -1.0  \n",
       "871                 -1.0  \n",
       "1123                -1.0  \n",
       "1396                -1.0  \n",
       "87                  -1.0  \n",
       "1482                -1.0  \n",
       "330                 -1.0  \n",
       "1238                -1.0  \n",
       "466                 -1.0  \n",
       "121                 -1.0  \n",
       "1044                -1.0  \n",
       "1095                -1.0  \n",
       "1130                -1.0  \n",
       "1294                -1.0  \n",
       "860                 -1.0  \n",
       "1459                -1.0  \n",
       "1126                -1.0  \n",
       "\n",
       "[1202 rows x 132 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import cross_val_predict, cross_val_score\\nimport matplotlib.pyplot as plt\\n\\nrandom_forest = RandomForestClassifier(random_state=42)\\ny_probas_forest_y = cross_val_predict(random_forest, x_train, y_train_youtube, cv=10, method=\"predict_proba\")\\ny_probas_forest_n = cross_val_predict(random_forest, x_train, y_train_netflix, cv=10, method=\"predict_proba\")\\ny_probas_forest_t = cross_val_predict(random_forest, x_train, y_train_twitch, cv=10, method=\"predict_proba\")\\ny_probas_forest = cross_val_predict(random_forest, x_train, y_train, cv=10, method=\"predict_proba\")\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest_y = cross_val_predict(random_forest, x_train, y_train_youtube, cv=10, method=\"predict_proba\")\n",
    "y_probas_forest_n = cross_val_predict(random_forest, x_train, y_train_netflix, cv=10, method=\"predict_proba\")\n",
    "y_probas_forest_t = cross_val_predict(random_forest, x_train, y_train_twitch, cv=10, method=\"predict_proba\")\n",
    "y_probas_forest = cross_val_predict(random_forest, x_train, y_train, cv=10, method=\"predict_proba\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_scores_forest_y = y_probas_forest_y[:, 1]\\ny_scores_forest_n = y_probas_forest_n[:, 1]\\ny_scores_forest_t = y_probas_forest_t[:, 1]\\n\\nfpr_forest_y, tpr_forest_y, thresholds_forest_y = roc_curve(y_train_youtube, y_scores_forest_y)\\nfpr_forest_n, tpr_forest_n, thresholds_forest_n = roc_curve(y_train_netflix, y_scores_forest_n)\\nfpr_forest_t, tpr_forest_t, thresholds_forest_t = roc_curve(y_train_twitch, y_scores_forest_t)\\n#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train, y_probas_forest)\\n\\n\\nplot_roc_curve(fpr_forest_y, tpr_forest_y, \"YouTube\")\\nplot_roc_curve(fpr_forest_n, tpr_forest_n, \"Netflix\")\\nplot_roc_curve(fpr_forest_t, tpr_forest_t, \"Twitch\")\\n#plot_roc_curve(fpr_forest, tpr_forest, \"Multiclass\")\\n\\nplt.legend(loc=\"lower right\")\\nplt.show()\\n#cvs = cross_val_score(random_forest, x_train, y_train, cv=10, scoring=\\'accuracy\\')\\n#accuracy = sum(cvs)/len(cvs)\\n#print(\"Accuracy: \" + str(accuracy))\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_scores_forest_y = y_probas_forest_y[:, 1]\n",
    "y_scores_forest_n = y_probas_forest_n[:, 1]\n",
    "y_scores_forest_t = y_probas_forest_t[:, 1]\n",
    "\n",
    "fpr_forest_y, tpr_forest_y, thresholds_forest_y = roc_curve(y_train_youtube, y_scores_forest_y)\n",
    "fpr_forest_n, tpr_forest_n, thresholds_forest_n = roc_curve(y_train_netflix, y_scores_forest_n)\n",
    "fpr_forest_t, tpr_forest_t, thresholds_forest_t = roc_curve(y_train_twitch, y_scores_forest_t)\n",
    "#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train, y_probas_forest)\n",
    "\n",
    "\n",
    "plot_roc_curve(fpr_forest_y, tpr_forest_y, \"YouTube\")\n",
    "plot_roc_curve(fpr_forest_n, tpr_forest_n, \"Netflix\")\n",
    "plot_roc_curve(fpr_forest_t, tpr_forest_t, \"Twitch\")\n",
    "#plot_roc_curve(fpr_forest, tpr_forest, \"Multiclass\")\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "#cvs = cross_val_score(random_forest, x_train, y_train, cv=10, scoring='accuracy')\n",
    "#accuracy = sum(cvs)/len(cvs)\n",
    "#print(\"Accuracy: \" + str(accuracy))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrandom_forest.fit(x_train, y_train)\\npredictions = random_forest.predict(x_test)\\nconf_mx = confusion_matrix(y_test, predictions)\\nplt.matshow(conf_mx, cmap=plt.cm.gray)\\nconf_mx\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "random_forest.fit(x_train, y_train)\n",
    "predictions = random_forest.predict(x_test)\n",
    "conf_mx = confusion_matrix(y_test, predictions)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "conf_mx\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search_acc = GridSearchCV(random_forest, params, cv=10, scoring='accuracy')\n",
    "#grid_search_acc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best2 = grid_search_acc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(zip(grid_search.best_estimator_.feature_importances_, basic_stats), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Final evaluation\\nrf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion=\\'entropy\\', max_depth=9, max_features=\\'log2\\', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1, oob_score=False, random_state=42, verbose=0, warm_start=False)\\nrf.fit(x_train, y_train)\\nprint(\"Accuracy train set: \" + str(sum(rf.predict(x_train) == y_train)/float(len(y_train))))\\nprint(\"Accuracy test set: \" + str(sum(rf.predict(x_test) == y_test)/float(len(y_test))))\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Final evaluation\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy', max_depth=9, max_features='log2', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1, oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "rf.fit(x_train, y_train)\n",
    "print(\"Accuracy train set: \" + str(sum(rf.predict(x_train) == y_train)/float(len(y_train))))\n",
    "print(\"Accuracy test set: \" + str(sum(rf.predict(x_test) == y_test)/float(len(y_test))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncrossval = cross_val_predict(rf, x_train, y_train, cv=10, method=\"predict_proba\")\\ncrossvalscore = cross_val_score(rf, x_train, y_train, cv=10, scoring=\"accuracy\")\\nprint(\"\\tCrossValScore: \" + str(sum(crossvalscore)/len(cv_yt)))\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "crossval = cross_val_predict(rf, x_train, y_train, cv=10, method=\"predict_proba\")\n",
    "crossvalscore = cross_val_score(rf, x_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "print(\"\\tCrossValScore: \" + str(sum(crossvalscore)/len(cv_yt)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def do_test_forest(model):\n",
    "    '''\n",
    "    y_probas_y = cross_val_predict(model, x_train, y_train_youtube, cv=10, method=\"predict_proba\")\n",
    "    y_probas_n = cross_val_predict(model, x_train, y_train_netflix, cv=10, method=\"predict_proba\")\n",
    "    y_probas_t = cross_val_predict(model, x_train, y_train_twitch, cv=10, method=\"predict_proba\")\n",
    "    y_probas = cross_val_predict(model, x_train, y_train, cv=10, method=\"predict_proba\")\n",
    "    \n",
    "    y_scores_y = y_probas_y[:, 1]\n",
    "    y_scores_n = y_probas_n[:, 1]\n",
    "    y_scores_t = y_probas_t[:, 1]\n",
    "\n",
    "    fpr_y, tpr_y, thresholds_y = roc_curve(y_train_youtube, y_scores_y)\n",
    "    fpr_n, tpr_n, thresholds_n = roc_curve(y_train_netflix, y_scores_n)\n",
    "    fpr_t, tpr_t, thresholds_t = roc_curve(y_train_twitch, y_scores_t)\n",
    "\n",
    "    plot_roc_curve(fpr_y, tpr_y, \"YouTube\")\n",
    "    plot_roc_curve(fpr_n, tpr_n, \"Netflix\")\n",
    "    plot_roc_curve(fpr_t, tpr_t, \"Twitch\")\n",
    "    #plot_roc_curve(fpr_forest, tpr_forest, \"Multiclass\")\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    #cvs = cross_val_score(random_forest, x_train, y_train, cv=10, scoring='accuracy')\n",
    "    #accuracy = sum(cvs)/len(cvs)\n",
    "    #print(\"Accuracy: \" + str(accuracy))\n",
    "    '''\n",
    "    cv_yt = cross_val_score(model, x_train, y_train_youtube, cv=10, scoring=\"accuracy\")\n",
    "    cv_nf = cross_val_score(model, x_train, y_train_netflix, cv=10, scoring=\"accuracy\")\n",
    "    cv_tw = cross_val_score(model, x_train, y_train_twitch, cv=10, scoring=\"accuracy\")\n",
    "    cv_mc = cross_val_score(model, x_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "    '''\n",
    "    print(\"YouTube: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_yt)/len(cv_yt)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_youtube, y_scores_y)))\n",
    "    print(\"Netflix: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_nf)/len(cv_nf)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_netflix, y_scores_n)))\n",
    "    print(\"Twitch: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_tw)/len(cv_tw)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_twitch, y_scores_t)))\n",
    "    print(\"Multiclass: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_mc)/len(cv_mc)))\n",
    "    '''\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    conf_mx = confusion_matrix(y_test, predictions)\n",
    "    plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "    print(conf_mx)\n",
    "    print(\"\\nAccuracy train set: \" + str(sum(model.predict(x_train) == y_train)/float(len(y_train))))\n",
    "    print(\"Accuracy test set: \" + str(sum(predictions == y_test)/float(len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def do_test_svm(model):    \n",
    "    '''\n",
    "    y_probas_y = cross_val_predict(model, x_train, y_train_youtube, cv=10, method=\"predict_proba\")\n",
    "    y_probas_n = cross_val_predict(model, x_train, y_train_netflix, cv=10, method=\"predict_proba\")\n",
    "    y_probas_t = cross_val_predict(model, x_train, y_train_twitch, cv=10, method=\"predict_proba\")\n",
    "    y_probas = cross_val_predict(model, x_train, y_train, cv=10, method=\"predict_proba\")\n",
    "    y_scores_y = y_probas_y[:, 1]\n",
    "    y_scores_n = y_probas_n[:, 1]\n",
    "    y_scores_t = y_probas_t[:, 1]\n",
    "    \n",
    "\n",
    "    fpr_y, tpr_y, thresholds_y = roc_curve(y_train_youtube, y_scores_y)\n",
    "    fpr_n, tpr_n, thresholds_n = roc_curve(y_train_netflix, y_scores_n)\n",
    "    fpr_t, tpr_t, thresholds_t = roc_curve(y_train_twitch, y_scores_t)\n",
    "    plot_roc_curve(fpr_y, tpr_y, \"YouTube\")\n",
    "    plot_roc_curve(fpr_n, tpr_n, \"Netflix\")\n",
    "    plot_roc_curve(fpr_t, tpr_t, \"Twitch\")\n",
    "    #plot_roc_curve(fpr_forest, tpr_forest, \"Multiclass\")\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    #cvs = cross_val_score(random_forest, x_train, y_train, cv=10, scoring='accuracy')\n",
    "    #accuracy = sum(cvs)/len(cvs)\n",
    "    #print(\"Accuracy: \" + str(accuracy))\n",
    "    '''\n",
    "    cv_yt = cross_val_score(model, x_train, y_train_youtube, cv=10, scoring=\"accuracy\")\n",
    "    cv_nf = cross_val_score(model, x_train, y_train_netflix, cv=10, scoring=\"accuracy\")\n",
    "    cv_tw = cross_val_score(model, x_train, y_train_twitch, cv=10, scoring=\"accuracy\")\n",
    "    \n",
    "    cv_mc = cross_val_score(model, x_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "    '''\n",
    "    print(\"YouTube: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_yt)/len(cv_yt)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_youtube, y_scores_y)))\n",
    "    print(\"Netflix: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_nf)/len(cv_nf)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_netflix, y_scores_n)))\n",
    "    print(\"Twitch: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_tw)/len(cv_tw)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_twitch, y_scores_t)))\n",
    "    '''\n",
    "    print(\"Multiclass: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_mc)/len(cv_mc)))\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    conf_mx = confusion_matrix(y_test, predictions)\n",
    "    plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "    print(conf_mx)\n",
    "    print(\"\\nAccuracy train set: \" + str(sum(model.predict(x_train) == y_train)/float(len(y_train))))\n",
    "    print(\"Accuracy test set: \" + str(sum(predictions == y_test)/float(len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test_knn(model):\n",
    "    \n",
    "    y_probas_y = cross_val_predict(model, x_train, y_train_youtube, cv=10, method=\"predict_proba\")\n",
    "    y_probas_n = cross_val_predict(model, x_train, y_train_netflix, cv=10, method=\"predict_proba\")\n",
    "    y_probas_t = cross_val_predict(model, x_train, y_train_twitch, cv=10, method=\"predict_proba\")\n",
    "    y_probas = cross_val_predict(model, x_train, y_train, cv=10, method=\"predict_proba\")\n",
    "    y_scores_y = y_probas_y[:, 1]\n",
    "    y_scores_n = y_probas_n[:, 1]\n",
    "    y_scores_t = y_probas_t[:, 1]\n",
    "    \n",
    "\n",
    "    fpr_y, tpr_y, thresholds_y = roc_curve(y_train_youtube, y_scores_y)\n",
    "    fpr_n, tpr_n, thresholds_n = roc_curve(y_train_netflix, y_scores_n)\n",
    "    fpr_t, tpr_t, thresholds_t = roc_curve(y_train_twitch, y_scores_t)\n",
    "    plot_roc_curve(fpr_y, tpr_y, \"YouTube\")\n",
    "    plot_roc_curve(fpr_n, tpr_n, \"Netflix\")\n",
    "    plot_roc_curve(fpr_t, tpr_t, \"Twitch\")\n",
    "    #plot_roc_curve(fpr_forest, tpr_forest, \"Multiclass\")\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    #cvs = cross_val_score(random_forest, x_train, y_train, cv=10, scoring='accuracy')\n",
    "    #accuracy = sum(cvs)/len(cvs)\n",
    "    #print(\"Accuracy: \" + str(accuracy))\n",
    "    \n",
    "    cv_yt = cross_val_score(model, x_train, y_train_youtube, cv=10, scoring=\"accuracy\")\n",
    "    cv_nf = cross_val_score(model, x_train, y_train_netflix, cv=10, scoring=\"accuracy\")\n",
    "    cv_tw = cross_val_score(model, x_train, y_train_twitch, cv=10, scoring=\"accuracy\")\n",
    "    \n",
    "    cv_mc = cross_val_score(model, x_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "    \n",
    "    print(\"YouTube: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_yt)/len(cv_yt)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_youtube, y_scores_y)))\n",
    "    print(\"Netflix: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_nf)/len(cv_nf)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_netflix, y_scores_n)))\n",
    "    print(\"Twitch: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_tw)/len(cv_tw)) + \"\\n\\tRocAucScore:  \" + str(roc_auc_score(y_train_twitch, y_scores_t)))\n",
    "    \n",
    "    print(\"Multiclass: \")\n",
    "    print(\"\\tCrossValScore: \" + str(sum(cv_mc)/len(cv_mc)))\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    conf_mx = confusion_matrix(y_test, predictions)\n",
    "    plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "    print(conf_mx)\n",
    "    print(\"\\nAccuracy train set: \" + str(sum(model.predict(x_train) == y_train)/float(len(y_train))))\n",
    "    print(\"Accuracy test set: \" + str(sum(predictions == y_test)/float(len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Random Forest------\n",
      "[[ 40   0   2   0]\n",
      " [  0  81   2   0]\n",
      " [  3   2 114   1]\n",
      " [  0   0   0  56]]\n",
      "\n",
      "Accuracy train set: 1.0\n",
      "Accuracy test set: 0.9667774086378738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"-----OvO Classifier Random Forest------\")\\n\\nrf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion=\\'entropy\\', max_depth=9,\\n                            max_features=\\'log2\\', max_leaf_nodes=None, min_impurity_decrease=0.0,\\n                            min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\\n                            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1, oob_score=False,\\n                            random_state=42, verbose=0, warm_start=False)\\nrf = OneVsOneClassifier(rf)\\ndo_test_forest(rf)\\n\\nprint(\"----------SVM-----------\")\\nsvm = SVC(random_state=42, probability=True)\\ndo_test_svm(svm)\\n\\nprint(\"----------Knn-----------\")\\nknn = KNeighborsClassifier()\\ndo_test_knn(knn)\\n\\nprint(\"-----Neural Network-----\")\\nnn = MLPClassifier()\\ndo_test_knn(nn)\\n\\n\\nprint(\"--------AdaBoost Random Forest--------\")\\n\\nrf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion=\\'entropy\\', max_depth=9,\\n                            max_features=\\'log2\\', max_leaf_nodes=None, min_impurity_decrease=0.0,\\n                            min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\\n                            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1, oob_score=False,\\n                            random_state=42, verbose=0, warm_start=False)\\n\\nada_clf = AdaBoostClassifier(\\n    rf,\\n    algorithm=\"SAMME.R\", learning_rate=0.5\\n)\\ndo_test_forest(ada_clf)\\n\\nprint(\"---------Decision Tree------\")\\ndt = DecisionTreeClassifier(random_state=42)\\n\\ndo_test_forest(dt)\\n\\nprint(\"--------AdaBoost Decision Tree--------\")\\n\\ndt = DecisionTreeClassifier(random_state=42)\\n\\nada_clf = AdaBoostClassifier(\\n    dt,\\n    algorithm=\"SAMME.R\", learning_rate=0.5\\n)\\ndo_test_forest(ada_clf)\\n\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"-----Random Forest------\")\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=9, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "do_test_forest(rf)\n",
    "\n",
    "'''\n",
    "print(\"-----OvO Classifier Random Forest------\")\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy', max_depth=9,\n",
    "                            max_features='log2', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                            min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
    "                            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1, oob_score=False,\n",
    "                            random_state=42, verbose=0, warm_start=False)\n",
    "rf = OneVsOneClassifier(rf)\n",
    "do_test_forest(rf)\n",
    "\n",
    "print(\"----------SVM-----------\")\n",
    "svm = SVC(random_state=42, probability=True)\n",
    "do_test_svm(svm)\n",
    "\n",
    "print(\"----------Knn-----------\")\n",
    "knn = KNeighborsClassifier()\n",
    "do_test_knn(knn)\n",
    "\n",
    "print(\"-----Neural Network-----\")\n",
    "nn = MLPClassifier()\n",
    "do_test_knn(nn)\n",
    "\n",
    "\n",
    "print(\"--------AdaBoost Random Forest--------\")\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy', max_depth=9,\n",
    "                            max_features='log2', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                            min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
    "                            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1, oob_score=False,\n",
    "                            random_state=42, verbose=0, warm_start=False)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    rf,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5\n",
    ")\n",
    "do_test_forest(ada_clf)\n",
    "\n",
    "print(\"---------Decision Tree------\")\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "do_test_forest(dt)\n",
    "\n",
    "print(\"--------AdaBoost Decision Tree--------\")\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    dt,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5\n",
    ")\n",
    "do_test_forest(ada_clf)\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = dict()\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "params['forest'] = {\n",
    "    'max_depth' : [6,7,8,9],\n",
    "    'n_estimators': [30,100,300],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_leaf' : [1, 2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 3, 10],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(random_forest, params['forest'], cv=10, scoring='accuracy')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_random_forest = grid_search.best_estimator_\n",
    "\n",
    "predictions = best_random_forest.predict(x_test)\n",
    "conf_mx = confusion_matrix(y_test, predictions)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "print(conf_mx)\n",
    "print(\"\\nAccuracy train set: \" + str(sum(best_random_forest.predict(x_train) == y_train)/float(len(y_train))))\n",
    "print(\"Accuracy test set: \" + str(sum(predictions == y_test)/float(len(y_test))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Random Forest------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3c6869eccbb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             warm_start=False)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdo_test_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-b767a046dc29>\u001b[0m in \u001b[0;36mdo_test_forest\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcv_nf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_netflix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mcv_tw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_twitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mcv_mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     '''\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"YouTube: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/thesis/env/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"-----Random Forest------\")\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=9, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "do_test_forest(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/rf_model_01s.sav']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(rf, '../models/rf_model_01s.sav') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.65946734 -1.73477919 -1.2318347  -4.22145108]\n",
      " [-0.34487931 -4.11526472 -1.37651383 -3.77594527]\n",
      " [-0.16042623 -3.82198385 -2.0832087  -6.31718965]\n",
      " [-0.49440497 -2.76821807 -1.18112638 -3.8941985 ]\n",
      " [-0.13421028 -4.403363   -2.19051664 -6.50311376]\n",
      " [-0.30400206 -3.16321299 -1.53384557 -5.48550383]\n",
      " [-0.17031451 -4.36427963 -1.9777458  -5.20376361]\n",
      " [-0.1332101  -4.05725409 -2.246051   -6.43394457]\n",
      " [-0.10791961 -3.83569323 -2.52406313 -7.45159518]\n",
      " [-0.25609308 -3.09667795 -1.73380679 -5.49186039]\n",
      " [-0.06928215 -4.4673744  -2.91726127 -6.58740486]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(base_folder):\n",
    "    for name in files:\n",
    "        if name == 'cap3.csv':\n",
    "            test = pd.read_csv(os.path.join(str(path), str(name)))\n",
    "test = test.drop(columns=['Unnamed: 0']).reset_index()\n",
    "test.drop(columns=['index', 'up_packet_silence_mean', 'down_packet_silence_mean',\n",
    "                      'down_packet_longest_silence', 'down_packet_shortest_silence','label'], inplace=True)\n",
    "# Imputer for NaN\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "imputer.fit(test)\n",
    "test = pd.DataFrame(imputer.transform(test), columns=test.columns)\n",
    "print(rf.predict_log_proba(test))\n",
    "print(rf.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "rf = joblib.load('../models/rf_model_01s.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acestream\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(prevlabel[4000])\n",
    "dataset['label'][4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>up_bytes_mean</th>\n",
       "      <th>up_bytes_median</th>\n",
       "      <th>up_bytes_std</th>\n",
       "      <th>up_bytes_var</th>\n",
       "      <th>up_bytes_skew</th>\n",
       "      <th>up_bytes_kurt</th>\n",
       "      <th>up_bytes_perc25</th>\n",
       "      <th>up_bytes_perc50</th>\n",
       "      <th>up_bytes_perc75</th>\n",
       "      <th>up_bytes_perc90</th>\n",
       "      <th>...</th>\n",
       "      <th>down_packet_1min_y</th>\n",
       "      <th>down_packet_2min_y</th>\n",
       "      <th>down_packet_3min_y</th>\n",
       "      <th>down_packet_4min_y</th>\n",
       "      <th>down_packet_5min_y</th>\n",
       "      <th>down_packet_1min_x</th>\n",
       "      <th>down_packet_2min_x</th>\n",
       "      <th>down_packet_3min_x</th>\n",
       "      <th>down_packet_4min_x</th>\n",
       "      <th>down_packet_5min_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049954</td>\n",
       "      <td>-0.403884</td>\n",
       "      <td>0.903263</td>\n",
       "      <td>0.815885</td>\n",
       "      <td>0.936888</td>\n",
       "      <td>-0.152483</td>\n",
       "      <td>-0.777905</td>\n",
       "      <td>-0.403884</td>\n",
       "      <td>0.496817</td>\n",
       "      <td>1.335181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.071279</td>\n",
       "      <td>3.978398</td>\n",
       "      <td>2.497202</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.555438</td>\n",
       "      <td>-1.038336</td>\n",
       "      <td>0.953788</td>\n",
       "      <td>0.909712</td>\n",
       "      <td>2.042770</td>\n",
       "      <td>3.353170</td>\n",
       "      <td>-1.076309</td>\n",
       "      <td>-1.038336</td>\n",
       "      <td>-0.688625</td>\n",
       "      <td>0.728165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015163</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.814609</td>\n",
       "      <td>6.727171</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.429697</td>\n",
       "      <td>-0.797330</td>\n",
       "      <td>1.049213</td>\n",
       "      <td>1.100848</td>\n",
       "      <td>1.963251</td>\n",
       "      <td>2.620611</td>\n",
       "      <td>-1.040970</td>\n",
       "      <td>-0.797330</td>\n",
       "      <td>-0.604283</td>\n",
       "      <td>1.413431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.262960</td>\n",
       "      <td>3.220981</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.290295</td>\n",
       "      <td>-0.852862</td>\n",
       "      <td>1.105632</td>\n",
       "      <td>1.222422</td>\n",
       "      <td>1.520949</td>\n",
       "      <td>1.379564</td>\n",
       "      <td>-1.076309</td>\n",
       "      <td>-0.852862</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>1.490957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013611</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.676306</td>\n",
       "      <td>7.336032</td>\n",
       "      <td>4.808627</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.490188</td>\n",
       "      <td>0.728495</td>\n",
       "      <td>1.230044</td>\n",
       "      <td>1.513008</td>\n",
       "      <td>0.312373</td>\n",
       "      <td>-0.971798</td>\n",
       "      <td>-0.726433</td>\n",
       "      <td>0.728495</td>\n",
       "      <td>1.389561</td>\n",
       "      <td>1.860390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.669475</td>\n",
       "      <td>4.087589</td>\n",
       "      <td>2.650473</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.412808</td>\n",
       "      <td>0.602065</td>\n",
       "      <td>0.860344</td>\n",
       "      <td>0.740192</td>\n",
       "      <td>-0.417224</td>\n",
       "      <td>-1.152910</td>\n",
       "      <td>-0.262419</td>\n",
       "      <td>0.602065</td>\n",
       "      <td>1.011425</td>\n",
       "      <td>1.422233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.237534</td>\n",
       "      <td>6.036658</td>\n",
       "      <td>2.524395</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.350947</td>\n",
       "      <td>0.470368</td>\n",
       "      <td>0.871598</td>\n",
       "      <td>0.759682</td>\n",
       "      <td>0.216610</td>\n",
       "      <td>-0.865017</td>\n",
       "      <td>-0.559836</td>\n",
       "      <td>0.470368</td>\n",
       "      <td>0.849711</td>\n",
       "      <td>1.411894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.674702</td>\n",
       "      <td>7.140066</td>\n",
       "      <td>3.768688</td>\n",
       "      <td>2.538102</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.268645</td>\n",
       "      <td>-0.620746</td>\n",
       "      <td>1.062333</td>\n",
       "      <td>1.128552</td>\n",
       "      <td>1.905095</td>\n",
       "      <td>3.268406</td>\n",
       "      <td>-1.053646</td>\n",
       "      <td>-0.620746</td>\n",
       "      <td>-0.213910</td>\n",
       "      <td>1.118297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.660826</td>\n",
       "      <td>3.291511</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.061178</td>\n",
       "      <td>-0.247054</td>\n",
       "      <td>0.810107</td>\n",
       "      <td>0.656273</td>\n",
       "      <td>0.315406</td>\n",
       "      <td>-1.275492</td>\n",
       "      <td>-0.870641</td>\n",
       "      <td>-0.247054</td>\n",
       "      <td>0.627636</td>\n",
       "      <td>1.170910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.988808</td>\n",
       "      <td>5.358670</td>\n",
       "      <td>2.497202</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.236846</td>\n",
       "      <td>0.320672</td>\n",
       "      <td>0.891537</td>\n",
       "      <td>0.794837</td>\n",
       "      <td>-0.037296</td>\n",
       "      <td>-1.229062</td>\n",
       "      <td>-0.767698</td>\n",
       "      <td>0.320672</td>\n",
       "      <td>0.949033</td>\n",
       "      <td>1.227913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016661</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.337687</td>\n",
       "      <td>6.949335</td>\n",
       "      <td>3.118009</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.144833</td>\n",
       "      <td>0.340536</td>\n",
       "      <td>0.743961</td>\n",
       "      <td>0.553478</td>\n",
       "      <td>-0.272444</td>\n",
       "      <td>-1.121968</td>\n",
       "      <td>-0.596491</td>\n",
       "      <td>0.340536</td>\n",
       "      <td>0.604644</td>\n",
       "      <td>1.026987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.600851</td>\n",
       "      <td>7.063154</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.087574</td>\n",
       "      <td>0.163513</td>\n",
       "      <td>0.785633</td>\n",
       "      <td>0.617219</td>\n",
       "      <td>-0.085402</td>\n",
       "      <td>-1.405019</td>\n",
       "      <td>-0.775600</td>\n",
       "      <td>0.163513</td>\n",
       "      <td>0.701606</td>\n",
       "      <td>1.137678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.454343</td>\n",
       "      <td>5.812112</td>\n",
       "      <td>3.151962</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    up_bytes_mean  up_bytes_median  up_bytes_std  up_bytes_var  up_bytes_skew  \\\n",
       "0       -0.049954        -0.403884      0.903263      0.815885       0.936888   \n",
       "1       -0.555438        -1.038336      0.953788      0.909712       2.042770   \n",
       "2       -0.429697        -0.797330      1.049213      1.100848       1.963251   \n",
       "3       -0.290295        -0.852862      1.105632      1.222422       1.520949   \n",
       "4        0.490188         0.728495      1.230044      1.513008       0.312373   \n",
       "5        0.412808         0.602065      0.860344      0.740192      -0.417224   \n",
       "6        0.350947         0.470368      0.871598      0.759682       0.216610   \n",
       "7       -0.268645        -0.620746      1.062333      1.128552       1.905095   \n",
       "8       -0.061178        -0.247054      0.810107      0.656273       0.315406   \n",
       "9        0.236846         0.320672      0.891537      0.794837      -0.037296   \n",
       "10       0.144833         0.340536      0.743961      0.553478      -0.272444   \n",
       "11       0.087574         0.163513      0.785633      0.617219      -0.085402   \n",
       "\n",
       "    up_bytes_kurt  up_bytes_perc25  up_bytes_perc50  up_bytes_perc75  \\\n",
       "0       -0.152483        -0.777905        -0.403884         0.496817   \n",
       "1        3.353170        -1.076309        -1.038336        -0.688625   \n",
       "2        2.620611        -1.040970        -0.797330        -0.604283   \n",
       "3        1.379564        -1.076309        -0.852862         0.033406   \n",
       "4       -0.971798        -0.726433         0.728495         1.389561   \n",
       "5       -1.152910        -0.262419         0.602065         1.011425   \n",
       "6       -0.865017        -0.559836         0.470368         0.849711   \n",
       "7        3.268406        -1.053646        -0.620746        -0.213910   \n",
       "8       -1.275492        -0.870641        -0.247054         0.627636   \n",
       "9       -1.229062        -0.767698         0.320672         0.949033   \n",
       "10      -1.121968        -0.596491         0.340536         0.604644   \n",
       "11      -1.405019        -0.775600         0.163513         0.701606   \n",
       "\n",
       "    up_bytes_perc90         ...          down_packet_1min_y  \\\n",
       "0          1.335181         ...                    0.002346   \n",
       "1          0.728165         ...                    0.015163   \n",
       "2          1.413431         ...                    0.000837   \n",
       "3          1.490957         ...                    0.013611   \n",
       "4          1.860390         ...                    0.001233   \n",
       "5          1.422233         ...                    0.008492   \n",
       "6          1.411894         ...                    0.003404   \n",
       "7          1.118297         ...                    0.002405   \n",
       "8          1.170910         ...                    0.006532   \n",
       "9          1.227913         ...                    0.016661   \n",
       "10         1.026987         ...                    0.001585   \n",
       "11         1.137678         ...                    0.001604   \n",
       "\n",
       "    down_packet_2min_y  down_packet_3min_y  down_packet_4min_y  \\\n",
       "0             0.001808            0.001815           -1.000000   \n",
       "1             0.000547           -1.000000           -1.000000   \n",
       "2             0.002284           -1.000000           -1.000000   \n",
       "3             0.002952            0.002953           -1.000000   \n",
       "4             0.004270            0.003137           -1.000000   \n",
       "5             0.002504            0.000737           -1.000000   \n",
       "6             0.006488            0.001413            0.003516   \n",
       "7             0.002918           -1.000000           -1.000000   \n",
       "8             0.004598            0.000632           -1.000000   \n",
       "9             0.001908            0.000587           -1.000000   \n",
       "10            0.002463           -1.000000           -1.000000   \n",
       "11            0.004513            0.010919           -1.000000   \n",
       "\n",
       "    down_packet_5min_y  down_packet_1min_x  down_packet_2min_x  \\\n",
       "0                 -1.0           11.071279            3.978398   \n",
       "1                 -1.0           11.814609            6.727171   \n",
       "2                 -1.0           10.262960            3.220981   \n",
       "3                 -1.0           12.676306            7.336032   \n",
       "4                 -1.0            9.669475            4.087589   \n",
       "5                 -1.0           13.237534            6.036658   \n",
       "6                 -1.0           13.674702            7.140066   \n",
       "7                 -1.0            7.660826            3.291511   \n",
       "8                 -1.0            9.988808            5.358670   \n",
       "9                 -1.0           12.337687            6.949335   \n",
       "10                -1.0           13.600851            7.063154   \n",
       "11                -1.0           13.454343            5.812112   \n",
       "\n",
       "    down_packet_3min_x  down_packet_4min_x  down_packet_5min_x  \n",
       "0             2.497202           -1.000000                -1.0  \n",
       "1            -1.000000           -1.000000                -1.0  \n",
       "2            -1.000000           -1.000000                -1.0  \n",
       "3             4.808627           -1.000000                -1.0  \n",
       "4             2.650473           -1.000000                -1.0  \n",
       "5             2.524395           -1.000000                -1.0  \n",
       "6             3.768688            2.538102                -1.0  \n",
       "7            -1.000000           -1.000000                -1.0  \n",
       "8             2.497202           -1.000000                -1.0  \n",
       "9             3.118009           -1.000000                -1.0  \n",
       "10           -1.000000           -1.000000                -1.0  \n",
       "11            3.151962           -1.000000                -1.0  \n",
       "\n",
       "[12 rows x 132 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
